{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe01b71d320b45afb7f7f5c8673d8701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc7697116590430490b10897146fe4e9",
              "IPY_MODEL_bac44472f24c4f768ddf30d692279597",
              "IPY_MODEL_284a37f7bbdd445695b68fa085e23880"
            ],
            "layout": "IPY_MODEL_48833750ab374ee6a282fa5a3e56a6c5"
          }
        },
        "fc7697116590430490b10897146fe4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f5aa36c8eeb43d391e8bbd06a6d5a45",
            "placeholder": "​",
            "style": "IPY_MODEL_631b5f74dede42e497f6eedd5b3abef5",
            "value": "config.json: 100%"
          }
        },
        "bac44472f24c4f768ddf30d692279597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d952c1ebeae4e009b2e8f9d7ae8524e",
            "max": 1048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_687ef3e0b0604e108bfb672c05af6b2c",
            "value": 1048
          }
        },
        "284a37f7bbdd445695b68fa085e23880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a38cf21a21524b128845c3c13a600d8b",
            "placeholder": "​",
            "style": "IPY_MODEL_17520ac266cd40379938261b58b8670e",
            "value": " 1.05k/1.05k [00:00&lt;00:00, 87.3kB/s]"
          }
        },
        "48833750ab374ee6a282fa5a3e56a6c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f5aa36c8eeb43d391e8bbd06a6d5a45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631b5f74dede42e497f6eedd5b3abef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d952c1ebeae4e009b2e8f9d7ae8524e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "687ef3e0b0604e108bfb672c05af6b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a38cf21a21524b128845c3c13a600d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17520ac266cd40379938261b58b8670e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9da2af8b8cf7464a80a8699b9ca40e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4893dd86de74630a0d2a77f4e19e7c8",
              "IPY_MODEL_fab3d74f7f7f4adcba4dbed82fa07880",
              "IPY_MODEL_7178da544b454f1aba87e3e34300d035"
            ],
            "layout": "IPY_MODEL_e04972026ae844c2abc8418424a65d51"
          }
        },
        "e4893dd86de74630a0d2a77f4e19e7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_489abada765e453db169e18d36f067c0",
            "placeholder": "​",
            "style": "IPY_MODEL_474dcd46d1324c1ebe96c0c35aa7a6a8",
            "value": "configuration_falcon.py: 100%"
          }
        },
        "fab3d74f7f7f4adcba4dbed82fa07880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_378c4f1d033c4ffea720a09ac4059501",
            "max": 7163,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a99a62a301c42db8e87da90c5422294",
            "value": 7163
          }
        },
        "7178da544b454f1aba87e3e34300d035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c53c34dc55cf45099730e3d53072461c",
            "placeholder": "​",
            "style": "IPY_MODEL_a835de32a3cd47f89ad3a58e8a67aae4",
            "value": " 7.16k/7.16k [00:00&lt;00:00, 621kB/s]"
          }
        },
        "e04972026ae844c2abc8418424a65d51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489abada765e453db169e18d36f067c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474dcd46d1324c1ebe96c0c35aa7a6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "378c4f1d033c4ffea720a09ac4059501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a99a62a301c42db8e87da90c5422294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c53c34dc55cf45099730e3d53072461c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a835de32a3cd47f89ad3a58e8a67aae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b82454bcdfa4678aa2ec636fdc476e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d945400454f04e23b93d044d652f9365",
              "IPY_MODEL_4e0df1b16ad8491c828f2bf332d4c7ee",
              "IPY_MODEL_c61f962f484745b98330a3c56728f5f1"
            ],
            "layout": "IPY_MODEL_22d957e1c5df451e91e91501d6433a77"
          }
        },
        "d945400454f04e23b93d044d652f9365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_672cc526d7a84424992309c033a64ef1",
            "placeholder": "​",
            "style": "IPY_MODEL_76e19bbbb96045158e4ef080d62347e7",
            "value": "modeling_falcon.py: 100%"
          }
        },
        "4e0df1b16ad8491c828f2bf332d4c7ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_978583e6dbf54a00888aa70a896d1c94",
            "max": 56920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c61672cf86349cf87309dd81047e89e",
            "value": 56920
          }
        },
        "c61f962f484745b98330a3c56728f5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_360c1956e9444b818c53a91505bfe897",
            "placeholder": "​",
            "style": "IPY_MODEL_5076699430fa4397a40e06d3d228bd67",
            "value": " 56.9k/56.9k [00:00&lt;00:00, 3.66MB/s]"
          }
        },
        "22d957e1c5df451e91e91501d6433a77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "672cc526d7a84424992309c033a64ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e19bbbb96045158e4ef080d62347e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "978583e6dbf54a00888aa70a896d1c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c61672cf86349cf87309dd81047e89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "360c1956e9444b818c53a91505bfe897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5076699430fa4397a40e06d3d228bd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40cbd9af922b431cb80cda3726ae84c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7700cfcf02aa4700ace92dc83bdc818e",
              "IPY_MODEL_01aa2eab23114affb2a8a1ab6c8e32e0",
              "IPY_MODEL_0f841e594b064a43900033d6713bd0a0"
            ],
            "layout": "IPY_MODEL_c35b4cde98504d36a37bf34945b1202c"
          }
        },
        "7700cfcf02aa4700ace92dc83bdc818e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87ee5eca4042418f9688bcde3a722929",
            "placeholder": "​",
            "style": "IPY_MODEL_5655264f371e4d9bb193aa70c0902c12",
            "value": "pytorch_model.bin.index.json: 100%"
          }
        },
        "01aa2eab23114affb2a8a1ab6c8e32e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3257a34dd0e44125ba45ad632977eb93",
            "max": 16924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49c854dee0ca45d790210cd024458611",
            "value": 16924
          }
        },
        "0f841e594b064a43900033d6713bd0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ec1188689e74a9a8f9eef5355b763e3",
            "placeholder": "​",
            "style": "IPY_MODEL_ea0627431aee4cf3bc3c27be8199f67b",
            "value": " 16.9k/16.9k [00:00&lt;00:00, 1.58MB/s]"
          }
        },
        "c35b4cde98504d36a37bf34945b1202c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87ee5eca4042418f9688bcde3a722929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5655264f371e4d9bb193aa70c0902c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3257a34dd0e44125ba45ad632977eb93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c854dee0ca45d790210cd024458611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ec1188689e74a9a8f9eef5355b763e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea0627431aee4cf3bc3c27be8199f67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1013f68844eb45f88f3b7341b01c7e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42cb54666aca467888c20ad89264429b",
              "IPY_MODEL_a5a2f88e2796442da5d328c453025bf8",
              "IPY_MODEL_c862a93f65fb46c2a8b5b7b31cce9158"
            ],
            "layout": "IPY_MODEL_0f96110f6dc64bb9922ca8b2573d84c0"
          }
        },
        "42cb54666aca467888c20ad89264429b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80b4173d95fc47cf9141f3e25e9f547b",
            "placeholder": "​",
            "style": "IPY_MODEL_11cfbbcaa96c4b078d8f7f8711b113ce",
            "value": "Downloading shards: 100%"
          }
        },
        "a5a2f88e2796442da5d328c453025bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1f78cef2eeb4129bea382e6adfd0c6c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_315eb52f3c44478ba655e36fb48cf0ae",
            "value": 2
          }
        },
        "c862a93f65fb46c2a8b5b7b31cce9158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a99c6f1257440dea6a2292786b1f7d1",
            "placeholder": "​",
            "style": "IPY_MODEL_3ddcfb91d1e74e4db5264fd07302b26a",
            "value": " 2/2 [12:10&lt;00:00, 340.78s/it]"
          }
        },
        "0f96110f6dc64bb9922ca8b2573d84c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b4173d95fc47cf9141f3e25e9f547b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11cfbbcaa96c4b078d8f7f8711b113ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1f78cef2eeb4129bea382e6adfd0c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315eb52f3c44478ba655e36fb48cf0ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a99c6f1257440dea6a2292786b1f7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ddcfb91d1e74e4db5264fd07302b26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1b984f228c74e468a97f7e9bb939b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b93e9a81a10a45239f6c01bfdbb1f3b0",
              "IPY_MODEL_81de6200184c48f4b83e09465e600e86",
              "IPY_MODEL_bd3b1826efbe41959eb0161492605899"
            ],
            "layout": "IPY_MODEL_28d755b8ab37421cad3c739bb63b6980"
          }
        },
        "b93e9a81a10a45239f6c01bfdbb1f3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28bfb77eeede48739eae2e5a1357f9b9",
            "placeholder": "​",
            "style": "IPY_MODEL_79172884d4734d1c89abe3474c70541b",
            "value": "pytorch_model-00001-of-00002.bin: 100%"
          }
        },
        "81de6200184c48f4b83e09465e600e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9ad30f90064dc791a4eda4d90551d0",
            "max": 9951028193,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b29780074c694f858b4fed3f1a715d6a",
            "value": 9951028193
          }
        },
        "bd3b1826efbe41959eb0161492605899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe5d3ab7dd024f139c117d0316d996e4",
            "placeholder": "​",
            "style": "IPY_MODEL_04bde6b3b5ab40bda57af400afe88f06",
            "value": " 9.95G/9.95G [08:21&lt;00:00, 19.5MB/s]"
          }
        },
        "28d755b8ab37421cad3c739bb63b6980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28bfb77eeede48739eae2e5a1357f9b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79172884d4734d1c89abe3474c70541b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e9ad30f90064dc791a4eda4d90551d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29780074c694f858b4fed3f1a715d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe5d3ab7dd024f139c117d0316d996e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04bde6b3b5ab40bda57af400afe88f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "513d12e09cdc40ca8301e3734d618a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f0c4c6810dc41efad66cf5e0a224dab",
              "IPY_MODEL_121d6e16050a40eda273b2336de3b871",
              "IPY_MODEL_17277cfe4bff4781b4df900b9eaa3c9a"
            ],
            "layout": "IPY_MODEL_6bda15012f1b4d6a9a31a48800ba0c42"
          }
        },
        "5f0c4c6810dc41efad66cf5e0a224dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f6f43ed87e4b178b03f8c430ee9850",
            "placeholder": "​",
            "style": "IPY_MODEL_056203a18ba6461a809647b7705a697d",
            "value": "pytorch_model-00002-of-00002.bin: 100%"
          }
        },
        "121d6e16050a40eda273b2336de3b871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb2d65c0cd044179901bb1549c298534",
            "max": 4483421659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a47901970a6484dbe05b8985253d3f7",
            "value": 4483421659
          }
        },
        "17277cfe4bff4781b4df900b9eaa3c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb596c13ce434ef9bdb8e21648d9c9b2",
            "placeholder": "​",
            "style": "IPY_MODEL_77f29fab736e40dfbfff4ba3b741975f",
            "value": " 4.48G/4.48G [03:45&lt;00:00, 19.1MB/s]"
          }
        },
        "6bda15012f1b4d6a9a31a48800ba0c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f6f43ed87e4b178b03f8c430ee9850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "056203a18ba6461a809647b7705a697d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb2d65c0cd044179901bb1549c298534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a47901970a6484dbe05b8985253d3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb596c13ce434ef9bdb8e21648d9c9b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f29fab736e40dfbfff4ba3b741975f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d701dfe29e347b4a13454d96981c47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_118641a256e44c9fb2d70cb2465612a7",
              "IPY_MODEL_cda8a962312749788b439ab800228765",
              "IPY_MODEL_0ce3f006611c4e25b63f6d65cd4de765"
            ],
            "layout": "IPY_MODEL_d5ad0ff743f346c996cdce9f2a3d025b"
          }
        },
        "118641a256e44c9fb2d70cb2465612a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bb6783ddd254f78841a802ba16c20c2",
            "placeholder": "​",
            "style": "IPY_MODEL_e7bbf8cb39fc47c59f71adae02678e6f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cda8a962312749788b439ab800228765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b918e7c67e614ea09ff4f52e405e2a86",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18ee8bde91fe4d19954888dea60cae5b",
            "value": 2
          }
        },
        "0ce3f006611c4e25b63f6d65cd4de765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a12ef0bb434697b06fe00edba8b87a",
            "placeholder": "​",
            "style": "IPY_MODEL_3397e24ffdb84fbd8274d7969ee4c59f",
            "value": " 2/2 [00:15&lt;00:00,  7.26s/it]"
          }
        },
        "d5ad0ff743f346c996cdce9f2a3d025b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb6783ddd254f78841a802ba16c20c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7bbf8cb39fc47c59f71adae02678e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b918e7c67e614ea09ff4f52e405e2a86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ee8bde91fe4d19954888dea60cae5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7a12ef0bb434697b06fe00edba8b87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3397e24ffdb84fbd8274d7969ee4c59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27dfbb83231f493e8d1f0354099274f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59dcf3ecb9854852b144679271246550",
              "IPY_MODEL_d5350c7c9f5147138b24937384290b34",
              "IPY_MODEL_0311c28ae33a45f68a34083830bf83ce"
            ],
            "layout": "IPY_MODEL_ae4a447b109647be98d809ff93ce05ab"
          }
        },
        "59dcf3ecb9854852b144679271246550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52c6c56d204b4e4c910bd6c098c65768",
            "placeholder": "​",
            "style": "IPY_MODEL_f14716e9136b4de88788a28a9a9c26c0",
            "value": "generation_config.json: 100%"
          }
        },
        "d5350c7c9f5147138b24937384290b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d981990b5ad4917af587066cf005254",
            "max": 117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc4ae199a94e42d2a3d046260d36913b",
            "value": 117
          }
        },
        "0311c28ae33a45f68a34083830bf83ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a8e3e37b274b258e0de45950641bd8",
            "placeholder": "​",
            "style": "IPY_MODEL_75a6cedbb8304edd8183c090ccea9b89",
            "value": " 117/117 [00:00&lt;00:00, 10.8kB/s]"
          }
        },
        "ae4a447b109647be98d809ff93ce05ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52c6c56d204b4e4c910bd6c098c65768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14716e9136b4de88788a28a9a9c26c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d981990b5ad4917af587066cf005254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc4ae199a94e42d2a3d046260d36913b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60a8e3e37b274b258e0de45950641bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a6cedbb8304edd8183c090ccea9b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fc31a1a6e1a4c06b7d8a6233d2ed0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16291f89c7b1422f84d792902c91d228",
              "IPY_MODEL_2532f37c365142369a08f961d3afeacc",
              "IPY_MODEL_ca5cd3b0924543d6bb79a9495e25f947"
            ],
            "layout": "IPY_MODEL_5850fcff00bf46d4bd2e1033a47ad47a"
          }
        },
        "16291f89c7b1422f84d792902c91d228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7266fa5acbc8462d84a85721dcecc434",
            "placeholder": "​",
            "style": "IPY_MODEL_3ea6f02d2384454f8a1d46808d33b3ea",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2532f37c365142369a08f961d3afeacc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d644d15e20984a3bb55f16848f565e14",
            "max": 287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b48b387cf8f4094949cb9426310b963",
            "value": 287
          }
        },
        "ca5cd3b0924543d6bb79a9495e25f947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fcef39c0b1d4b1f9125df2d9886d910",
            "placeholder": "​",
            "style": "IPY_MODEL_52db933cee3c4808b9d5ef963a5d3865",
            "value": " 287/287 [00:00&lt;00:00, 25.6kB/s]"
          }
        },
        "5850fcff00bf46d4bd2e1033a47ad47a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7266fa5acbc8462d84a85721dcecc434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ea6f02d2384454f8a1d46808d33b3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d644d15e20984a3bb55f16848f565e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b48b387cf8f4094949cb9426310b963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fcef39c0b1d4b1f9125df2d9886d910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52db933cee3c4808b9d5ef963a5d3865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3caa9dc1b92f42d5b7f20892d33a038b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e80b802af59442beadc73add2949c0ed",
              "IPY_MODEL_cd4fa1efd30d4023b40de74a722a3b98",
              "IPY_MODEL_67911bd2bb224c66b7389b2c0d412012"
            ],
            "layout": "IPY_MODEL_1f44ee1667da45a88a7b5707b1467f9f"
          }
        },
        "e80b802af59442beadc73add2949c0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78972c8b400f4471b73b73c9d9396163",
            "placeholder": "​",
            "style": "IPY_MODEL_b983857d9e434701bafb102ab8a721f5",
            "value": "tokenizer.json: 100%"
          }
        },
        "cd4fa1efd30d4023b40de74a722a3b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d2fab1f94a47e4a069fd18e91aa993",
            "max": 2734130,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f85141fd7ce4dee9f272101edc39ee2",
            "value": 2734130
          }
        },
        "67911bd2bb224c66b7389b2c0d412012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a5f05d7dff9447cb18691fb14170d47",
            "placeholder": "​",
            "style": "IPY_MODEL_928626b790e44d72aad99a23d361d48f",
            "value": " 2.73M/2.73M [00:01&lt;00:00, 2.34MB/s]"
          }
        },
        "1f44ee1667da45a88a7b5707b1467f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78972c8b400f4471b73b73c9d9396163": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b983857d9e434701bafb102ab8a721f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8d2fab1f94a47e4a069fd18e91aa993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f85141fd7ce4dee9f272101edc39ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a5f05d7dff9447cb18691fb14170d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "928626b790e44d72aad99a23d361d48f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0331345d3298429898469e2dfb7994cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ac3b37de6c948219e0790a76ec54cd4",
              "IPY_MODEL_1e8852d417ff447fa4c637440da832e8",
              "IPY_MODEL_c0b56a2c388e451f8750dd4c424cbd4b"
            ],
            "layout": "IPY_MODEL_976cb4e8648442cb9302a61676cd11e8"
          }
        },
        "2ac3b37de6c948219e0790a76ec54cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee4da4d89134ad5b748794c0bd5b1cf",
            "placeholder": "​",
            "style": "IPY_MODEL_0a1bb4fbb8654341bf33b1d28a982fc6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1e8852d417ff447fa4c637440da832e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_354192a206084d0fab16d38958700a1f",
            "max": 281,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31f1fb6766de4cb2a8eac32c30808da5",
            "value": 281
          }
        },
        "c0b56a2c388e451f8750dd4c424cbd4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd502d05b8e47478d12fec6a5316e5e",
            "placeholder": "​",
            "style": "IPY_MODEL_e7e1d812b5d141e5a2b2e8235fd602cf",
            "value": " 281/281 [00:00&lt;00:00, 27.1kB/s]"
          }
        },
        "976cb4e8648442cb9302a61676cd11e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee4da4d89134ad5b748794c0bd5b1cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1bb4fbb8654341bf33b1d28a982fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "354192a206084d0fab16d38958700a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f1fb6766de4cb2a8eac32c30808da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dd502d05b8e47478d12fec6a5316e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e1d812b5d141e5a2b2e8235fd602cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rderakhshan/AI-workforce/blob/main/Streamlit-Falcon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Un3WVx7-LHq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f79be4a2-c341-49c7-aad9-6baf20cef505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 24 19:34:47 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqqq pip\n",
        "!pip install bitsandbytes==0.40.0\n",
        "!pip install torch==2.1.0\n",
        "!pip install transformers==4.30.0\n",
        "!pip install accelerate==0.21.0\n",
        "!pip install xformers==0.0.20\n",
        "!pip install einops==0.6.1\n",
        "!pip install langchain==0.0.233\n",
        "!pip install chainlit==0.7.604"
      ],
      "metadata": {
        "id": "ETvVhniXVXYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "930f81fb-cb71-413a-f580-807244b6d777"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: bitsandbytes==0.40.0 in /usr/local/lib/python3.10/dist-packages (0.40.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch==2.1.0\n",
            "  Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0)\n",
            "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.3.101)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "Installing collected packages: triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.20 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.0 triton-2.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: transformers==4.30.0 in /usr/local/lib/python3.10/dist-packages (4.30.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2023.7.22)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: accelerate==0.21.0 in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.21.0) (12.3.101)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: xformers==0.0.20 in /usr/local/lib/python3.10/dist-packages (0.0.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.20) (1.23.5)\n",
            "Requirement already satisfied: pyre-extensions==0.0.29 in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.20) (0.0.29)\n",
            "Collecting torch==2.0.1 (from xformers==0.0.20)\n",
            "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers==0.0.20) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers==0.0.20) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers==0.0.20) (11.7.91)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1->xformers==0.0.20)\n",
            "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->xformers==0.0.20) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->xformers==0.0.20) (0.41.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.20) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.20) (17.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->xformers==0.0.20) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->xformers==0.0.20) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect->pyre-extensions==0.0.29->xformers==0.0.20) (1.0.0)\n",
            "Installing collected packages: triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0\n",
            "    Uninstalling torch-2.1.0:\n",
            "      Successfully uninstalled torch-2.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.1 triton-2.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: einops==0.6.1 in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: langchain==0.0.233 in /usr/local/lib/python3.10/dist-packages (0.0.233)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (3.8.6)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.0.6,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (0.0.5)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (2.8.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (1.23.5)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.233) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.233) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.233) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.233) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.233) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.233) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.233) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.233) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.233) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.233) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.233) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.233) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.233) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.233) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.233) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.233) (1.0.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: chainlit==0.7.604 in /usr/local/lib/python3.10/dist-packages (0.7.604)\n",
            "Requirement already satisfied: aiofiles<24.0.0,>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (23.2.1)\n",
            "Requirement already satisfied: asyncer<0.0.3,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (0.0.2)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (8.1.7)\n",
            "Requirement already satisfied: dataclasses_json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (0.5.14)\n",
            "Requirement already satisfied: fastapi<0.101,>=0.100 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (0.100.1)\n",
            "Requirement already satisfied: fastapi-socketio<0.0.11,>=0.0.10 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (0.0.10)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (1.2.0)\n",
            "Requirement already satisfied: httpx<0.25.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (0.24.1)\n",
            "Requirement already satisfied: lazify<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (0.4.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (1.5.8)\n",
            "Requirement already satisfied: packaging<24.0,>=23.1 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (1.10.13)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (2.8.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (1.0.0)\n",
            "Requirement already satisfied: python-graphql-client<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (0.4.3)\n",
            "Requirement already satisfied: python-multipart<0.0.7,>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (0.0.6)\n",
            "Requirement already satisfied: syncer<3.0.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (2.0.3)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (2.0.1)\n",
            "Requirement already satisfied: uptrace<2.0.0,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (1.21.0)\n",
            "Requirement already satisfied: uvicorn<0.24.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (0.23.2)\n",
            "Requirement already satisfied: watchfiles<0.21.0,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from chainlit==0.7.604) (0.20.0)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from asyncer<0.0.3,>=0.0.2->chainlit==0.7.604) (3.7.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses_json<0.6.0,>=0.5.7->chainlit==0.7.604) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses_json<0.6.0,>=0.5.7->chainlit==0.7.604) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.101,>=0.100->chainlit==0.7.604) (0.27.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.101,>=0.100->chainlit==0.7.604) (4.5.0)\n",
            "Requirement already satisfied: python-socketio>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from fastapi-socketio<0.0.11,>=0.0.10->chainlit==0.7.604) (5.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.23.0->chainlit==0.7.604) (2023.7.22)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.23.0->chainlit==0.7.604) (0.17.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.23.0->chainlit==0.7.604) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.23.0->chainlit==0.7.604) (1.3.0)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (3.8.6)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (2.31.0)\n",
            "Requirement already satisfied: websockets>=5.0 in /usr/local/lib/python3.10/dist-packages (from python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (12.0)\n",
            "Requirement already satisfied: opentelemetry-api~=1.21 in /usr/local/lib/python3.10/dist-packages (from uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp~=1.21 in /usr/local/lib/python3.10/dist-packages (from uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation~=0.42b0 in /usr/local/lib/python3.10/dist-packages (from uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-sdk~=1.21 in /usr/local/lib/python3.10/dist-packages (from uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.21.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn<0.24.0,>=0.23.2->chainlit==0.7.604) (0.14.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.4.0->asyncer<0.0.3,>=0.0.2->chainlit==0.7.604) (1.1.3)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (6.8.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.21.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.21.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.21.0)\n",
            "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.21.0->opentelemetry-exporter-otlp~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.21.0->opentelemetry-exporter-otlp~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.61.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.21.0->opentelemetry-exporter-otlp~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.59.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.21.0->opentelemetry-exporter-otlp~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.21.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.21.0->opentelemetry-exporter-otlp~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.21.0)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.21.0->opentelemetry-exporter-otlp-proto-grpc==1.21.0->opentelemetry-exporter-otlp~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation~=0.42b0->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation~=0.42b0->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (1.14.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (0.42b0)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit==0.7.604) (0.22.1)\n",
            "Requirement already satisfied: python-engineio>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit==0.7.604) (4.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->python-graphql-client<0.5.0,>=0.4.3->chainlit==0.7.604) (2.0.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses_json<0.6.0,>=0.5.7->chainlit==0.7.604) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api~=1.21->uptrace<2.0.0,>=1.18.0->chainlit==0.7.604) (3.17.0)\n",
            "Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from python-engineio>=4.8.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit==0.7.604) (1.0.0)\n",
            "Requirement already satisfied: wsproto in /usr/local/lib/python3.10/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit==0.7.604) (1.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "work_dir = drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqGE4wBs6Rv3",
        "outputId": "da15052e-a9b4-42e2-8f19-41d6c64ea10c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/"
      ],
      "metadata": {
        "id": "vLn1hmxf6R0w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "8i96nuHs6mfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94eb7747-4b4a-4a7e-e431-6bc458191533"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI8VobW-6qWU",
        "outputId": "e4fdee66-7479-42aa-9b2b-5f7367004141"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAbSDSGC6R47",
        "outputId": "ba6cc366-dda1-4ecb-86d5-f8a35b06e455"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onreK0v46R8j",
        "outputId": "22816192-da02-41e5-ff7b-b837aaeb1bdd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Agreement-1.pdf   \u001b[0m\u001b[01;34m'BME PROJECT'\u001b[0m/      'Falcon 7B'      \u001b[01;34mThesis\u001b[0m/\n",
            " \u001b[01;34mAI\u001b[0m/               \u001b[01;34m'Colab Notebooks'\u001b[0m/   \u001b[01;34mFalcon-7B\u001b[0m/      USB.zip\n",
            " \u001b[01;34mAutomation\u001b[0m/        DOC004.PDF          Photos.zip      Utrecht.zip\n",
            " Automation.ipynb  \u001b[01;34m'Document Copy'\u001b[0m/     Residence.zip   Vahid_HostingAgreement_SignedScanned.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd AI/Falconchat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U4CxQmE6R_9",
        "outputId": "1d39e62c-99c1-4e36-d973-e808f5c5fd9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI/Falconchat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "S1bR6s-o6SDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7320c62-a9d6-43f7-cdc5-eb84ce4955ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chainlit.md  chainlit.py  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYcQshkn6SG_",
        "outputId": "ffbcaf35-d248-4b85-df99-205b45766ae2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package in 2.181s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit -q\n",
        "!pip install streamlit-chat"
      ],
      "metadata": {
        "id": "K8rxVdfz6SKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292d7274-81b5-4e0e-d0aa-b8882861b8ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: streamlit-chat in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit-chat) (1.28.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit-chat) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-chat) (4.0.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit-chat) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-chat) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit>=0.63->streamlit-chat) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-chat) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-chat) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-chat) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.13.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit-chat) (0.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQvuAkEfoCbP",
        "outputId": "fc5835c4-f938-405f-bb95-7e59e027f474"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 24 19:40:33 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run chainlit.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CPUw4zAZeAp",
        "outputId": "9d6c947c-7acc-4aac-919e-f4f71f07455f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l[..................] / rollbackFailedOptional: verb npm-session b5279f13750e1e6\u001b[0m\u001b[K\r[..................] / rollbackFailedOptional: verb npm-session b5279f13750e1e6\u001b[0m\u001b[K\r\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.236.129.119:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.265s\n",
            "your url is: https://wicked-bears-fry.loca.lt\n",
            "2023-11-24 22:47:09.525132: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 22:47:09.525190: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 22:47:09.525215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 22:47:10.755201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('http'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-hm-beccuc2qfx6y --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "\n",
            "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.49s/it]\n",
            "The model 'FalconForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.20s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: What are the large language models?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.42s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.28s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.03s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: what are the large language models?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.41s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: do their learning requires advanced math knowlwdge? if so, from which domains of math?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.47s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: I mean, if learning of large language models requires specifically what type of math knoledge?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:17<00:00,  8.68s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: what are the differences and similarities of violin and piano? Write down your answer in two paragraphs. \n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.40s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: write an short email to my manger and tell, it will be fruitful if you participate in the upcomming meeting next Wednesday. Note that, my manager's name is Melike. \n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.29s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Why earthquake happens? Write down your response in two paragraphs.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:17<00:00,  8.64s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: why ships do not sink in ocean?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.28s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: tell me a joke about fox.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.23s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Which programming language is suitable for piplining large language models?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.36s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: What couple of paragraphs about about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs)\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.27s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: What are the similiarities and differences of trading book and banking book portfolios in banks?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:17<00:00,  8.52s/it]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Probability of defauld, loss given default and exposure at default, are three main component in capital calculation. Write a paragraph summary about each of them.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMBIUf_ee9sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hKqo4uqe9uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L4fYdeBQe9wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fkms6jqGe9zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hL8TBR03e92X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tDfJYZcMe95O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8pvgrrzpe98G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RpNdvs4he9--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a1usx-LXe-Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8uTJ2Wxe-Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLEA6xjme-HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tRzxnoRpe-KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ygFW-Q0De-NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBiMoikKe-P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KkaL_cT4e-Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5y0FNg4Ke-Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1cPbdLZje-Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sFyD-VKe-bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hb055ROhe-ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mvWF3GMHe-hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qFy340W8e-kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AaAq4Sbee-m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gQmPPJg6e-pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C-GxNGWCe-sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import warnings\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.schema import BaseOutputParser\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    StoppingCriteria,\n",
        "    StoppingCriteriaList,\n",
        "    pipeline,\n",
        ")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1eINJNyg7rk",
        "outputId": "f533dc0a-534b-417b-a374-6cc7212657ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('http'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-hm-u8nry6ksa4xm --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained( MODEL_NAME, trust_remote_code = True,\\\n",
        "                                             load_in_8bit = True, device_map = \"auto\"\n",
        ")\n",
        "model = model.eval()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "print(f\"Model device: {model.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591,
          "referenced_widgets": [
            "fe01b71d320b45afb7f7f5c8673d8701",
            "fc7697116590430490b10897146fe4e9",
            "bac44472f24c4f768ddf30d692279597",
            "284a37f7bbdd445695b68fa085e23880",
            "48833750ab374ee6a282fa5a3e56a6c5",
            "4f5aa36c8eeb43d391e8bbd06a6d5a45",
            "631b5f74dede42e497f6eedd5b3abef5",
            "4d952c1ebeae4e009b2e8f9d7ae8524e",
            "687ef3e0b0604e108bfb672c05af6b2c",
            "a38cf21a21524b128845c3c13a600d8b",
            "17520ac266cd40379938261b58b8670e",
            "9da2af8b8cf7464a80a8699b9ca40e1c",
            "e4893dd86de74630a0d2a77f4e19e7c8",
            "fab3d74f7f7f4adcba4dbed82fa07880",
            "7178da544b454f1aba87e3e34300d035",
            "e04972026ae844c2abc8418424a65d51",
            "489abada765e453db169e18d36f067c0",
            "474dcd46d1324c1ebe96c0c35aa7a6a8",
            "378c4f1d033c4ffea720a09ac4059501",
            "9a99a62a301c42db8e87da90c5422294",
            "c53c34dc55cf45099730e3d53072461c",
            "a835de32a3cd47f89ad3a58e8a67aae4",
            "0b82454bcdfa4678aa2ec636fdc476e2",
            "d945400454f04e23b93d044d652f9365",
            "4e0df1b16ad8491c828f2bf332d4c7ee",
            "c61f962f484745b98330a3c56728f5f1",
            "22d957e1c5df451e91e91501d6433a77",
            "672cc526d7a84424992309c033a64ef1",
            "76e19bbbb96045158e4ef080d62347e7",
            "978583e6dbf54a00888aa70a896d1c94",
            "3c61672cf86349cf87309dd81047e89e",
            "360c1956e9444b818c53a91505bfe897",
            "5076699430fa4397a40e06d3d228bd67",
            "40cbd9af922b431cb80cda3726ae84c6",
            "7700cfcf02aa4700ace92dc83bdc818e",
            "01aa2eab23114affb2a8a1ab6c8e32e0",
            "0f841e594b064a43900033d6713bd0a0",
            "c35b4cde98504d36a37bf34945b1202c",
            "87ee5eca4042418f9688bcde3a722929",
            "5655264f371e4d9bb193aa70c0902c12",
            "3257a34dd0e44125ba45ad632977eb93",
            "49c854dee0ca45d790210cd024458611",
            "1ec1188689e74a9a8f9eef5355b763e3",
            "ea0627431aee4cf3bc3c27be8199f67b",
            "1013f68844eb45f88f3b7341b01c7e28",
            "42cb54666aca467888c20ad89264429b",
            "a5a2f88e2796442da5d328c453025bf8",
            "c862a93f65fb46c2a8b5b7b31cce9158",
            "0f96110f6dc64bb9922ca8b2573d84c0",
            "80b4173d95fc47cf9141f3e25e9f547b",
            "11cfbbcaa96c4b078d8f7f8711b113ce",
            "a1f78cef2eeb4129bea382e6adfd0c6c",
            "315eb52f3c44478ba655e36fb48cf0ae",
            "5a99c6f1257440dea6a2292786b1f7d1",
            "3ddcfb91d1e74e4db5264fd07302b26a",
            "e1b984f228c74e468a97f7e9bb939b73",
            "b93e9a81a10a45239f6c01bfdbb1f3b0",
            "81de6200184c48f4b83e09465e600e86",
            "bd3b1826efbe41959eb0161492605899",
            "28d755b8ab37421cad3c739bb63b6980",
            "28bfb77eeede48739eae2e5a1357f9b9",
            "79172884d4734d1c89abe3474c70541b",
            "9e9ad30f90064dc791a4eda4d90551d0",
            "b29780074c694f858b4fed3f1a715d6a",
            "fe5d3ab7dd024f139c117d0316d996e4",
            "04bde6b3b5ab40bda57af400afe88f06",
            "513d12e09cdc40ca8301e3734d618a52",
            "5f0c4c6810dc41efad66cf5e0a224dab",
            "121d6e16050a40eda273b2336de3b871",
            "17277cfe4bff4781b4df900b9eaa3c9a",
            "6bda15012f1b4d6a9a31a48800ba0c42",
            "94f6f43ed87e4b178b03f8c430ee9850",
            "056203a18ba6461a809647b7705a697d",
            "bb2d65c0cd044179901bb1549c298534",
            "7a47901970a6484dbe05b8985253d3f7",
            "cb596c13ce434ef9bdb8e21648d9c9b2",
            "77f29fab736e40dfbfff4ba3b741975f",
            "0d701dfe29e347b4a13454d96981c47b",
            "118641a256e44c9fb2d70cb2465612a7",
            "cda8a962312749788b439ab800228765",
            "0ce3f006611c4e25b63f6d65cd4de765",
            "d5ad0ff743f346c996cdce9f2a3d025b",
            "2bb6783ddd254f78841a802ba16c20c2",
            "e7bbf8cb39fc47c59f71adae02678e6f",
            "b918e7c67e614ea09ff4f52e405e2a86",
            "18ee8bde91fe4d19954888dea60cae5b",
            "a7a12ef0bb434697b06fe00edba8b87a",
            "3397e24ffdb84fbd8274d7969ee4c59f",
            "27dfbb83231f493e8d1f0354099274f1",
            "59dcf3ecb9854852b144679271246550",
            "d5350c7c9f5147138b24937384290b34",
            "0311c28ae33a45f68a34083830bf83ce",
            "ae4a447b109647be98d809ff93ce05ab",
            "52c6c56d204b4e4c910bd6c098c65768",
            "f14716e9136b4de88788a28a9a9c26c0",
            "0d981990b5ad4917af587066cf005254",
            "fc4ae199a94e42d2a3d046260d36913b",
            "60a8e3e37b274b258e0de45950641bd8",
            "75a6cedbb8304edd8183c090ccea9b89",
            "0fc31a1a6e1a4c06b7d8a6233d2ed0f5",
            "16291f89c7b1422f84d792902c91d228",
            "2532f37c365142369a08f961d3afeacc",
            "ca5cd3b0924543d6bb79a9495e25f947",
            "5850fcff00bf46d4bd2e1033a47ad47a",
            "7266fa5acbc8462d84a85721dcecc434",
            "3ea6f02d2384454f8a1d46808d33b3ea",
            "d644d15e20984a3bb55f16848f565e14",
            "4b48b387cf8f4094949cb9426310b963",
            "4fcef39c0b1d4b1f9125df2d9886d910",
            "52db933cee3c4808b9d5ef963a5d3865",
            "3caa9dc1b92f42d5b7f20892d33a038b",
            "e80b802af59442beadc73add2949c0ed",
            "cd4fa1efd30d4023b40de74a722a3b98",
            "67911bd2bb224c66b7389b2c0d412012",
            "1f44ee1667da45a88a7b5707b1467f9f",
            "78972c8b400f4471b73b73c9d9396163",
            "b983857d9e434701bafb102ab8a721f5",
            "f8d2fab1f94a47e4a069fd18e91aa993",
            "3f85141fd7ce4dee9f272101edc39ee2",
            "5a5f05d7dff9447cb18691fb14170d47",
            "928626b790e44d72aad99a23d361d48f",
            "0331345d3298429898469e2dfb7994cf",
            "2ac3b37de6c948219e0790a76ec54cd4",
            "1e8852d417ff447fa4c637440da832e8",
            "c0b56a2c388e451f8750dd4c424cbd4b",
            "976cb4e8648442cb9302a61676cd11e8",
            "4ee4da4d89134ad5b748794c0bd5b1cf",
            "0a1bb4fbb8654341bf33b1d28a982fc6",
            "354192a206084d0fab16d38958700a1f",
            "31f1fb6766de4cb2a8eac32c30808da5",
            "6dd502d05b8e47478d12fec6a5316e5e",
            "e7e1d812b5d141e5a2b2e8235fd602cf"
          ]
        },
        "id": "iG_i70hRamsp",
        "outputId": "12d09353-b800-4115-cfae-951fa2294f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe01b71d320b45afb7f7f5c8673d8701"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_falcon.py:   0%|          | 0.00/7.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9da2af8b8cf7464a80a8699b9ca40e1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n",
            "- configuration_falcon.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "WARNING:transformers_modules.tiiuae.falcon-7b-instruct.cf4b3c42ce2fdfe24f753f0f0d179202fea59c99.configuration_falcon:\n",
            "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b82454bcdfa4678aa2ec636fdc476e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n",
            "- modeling_falcon.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40cbd9af922b431cb80cda3726ae84c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1013f68844eb45f88f3b7341b01c7e28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1b984f228c74e468a97f7e9bb939b73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "513d12e09cdc40ca8301e3734d618a52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d701dfe29e347b4a13454d96981c47b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27dfbb83231f493e8d1f0354099274f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fc31a1a6e1a4c06b7d8a6233d2ed0f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3caa9dc1b92f42d5b7f20892d33a038b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0331345d3298429898469e2dfb7994cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORFzZ0vFcyRB",
        "outputId": "cf250bd0-f1ad-4599-91ef-c48bd26fee3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 24 17:26:12 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P0    30W /  70W |   8153MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generation_config = model.generation_config\n",
        "generation_config.temperature = 0\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.max_new_tokens = 256\n",
        "generation_config.use_cache = False\n",
        "generation_config.repetition_penalty = 1.7\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id\n",
        "generation_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5orztoxc4NQ",
        "outputId": "bf9639e8-2d73-415f-9285-91ad0c2150d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerationConfig {\n",
              "  \"_from_model_config\": true,\n",
              "  \"bos_token_id\": 11,\n",
              "  \"eos_token_id\": 11,\n",
              "  \"max_new_tokens\": 256,\n",
              "  \"pad_token_id\": 11,\n",
              "  \"repetition_penalty\": 1.7,\n",
              "  \"temperature\": 0,\n",
              "  \"transformers_version\": \"4.30.0\",\n",
              "  \"use_cache\": false\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.config"
      ],
      "metadata": {
        "id": "AAq0jy9Fc4Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StopGenerationCriteria(StoppingCriteria):\n",
        "    def __init__(\n",
        "        self, tokens: List[List[str]], tokenizer: AutoTokenizer, device: torch.device\n",
        "    ):\n",
        "        stop_token_ids = [tokenizer.convert_tokens_to_ids(t) for t in tokens]\n",
        "        self.stop_token_ids = [\n",
        "            torch.tensor(x, dtype=torch.long, device=device) for x in stop_token_ids\n",
        "        ]\n",
        "\n",
        "    def __call__(\n",
        "        self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs\n",
        "    ) -> bool:\n",
        "        for stop_ids in self.stop_token_ids:\n",
        "            if torch.eq(input_ids[0][-len(stop_ids) :], stop_ids).all():\n",
        "                return True\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "O_kDqAfMc4T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stop_tokens = [[\"Human\", \":\"], [\"AI\", \":\"]]\n",
        "stopping_criteria = StoppingCriteriaList(\n",
        "    [StopGenerationCriteria(stop_tokens, tokenizer, model.device)]\n",
        ")"
      ],
      "metadata": {
        "id": "HDTGCtRJc4aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generation_pipeline = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    task=\"text-generation\",\n",
        "    stopping_criteria=stopping_criteria,\n",
        "    generation_config=generation_config,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generation_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ4db-z9c4dZ",
        "outputId": "195edd5e-1446-40f0-e22d-02f34d64753c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'FalconForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chain = ConversationChain(llm=llm)\n",
        "# print(chain.prompt.template)"
      ],
      "metadata": {
        "id": "f7ubkcCBc4hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "template = \"\"\"\n",
        "The following is a friendly conversation between a human and an AI.\n",
        "The AI is talkative and provides lots of specific details from its context.\n",
        "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Human: {input}\n",
        "AI:\"\"\".strip()\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
        "\n",
        "print(template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C7LFRYIe9Mq",
        "outputId": "9a40fca1-83d0-4e8b-934b-08fcf4bc3596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key = \"history\", k = 6, return_only_outputs = True)\n",
        "\n",
        "chain = ConversationChain(llm = llm, memory = memory, prompt = prompt, verbose = True)"
      ],
      "metadata": {
        "id": "RsVSmk--enBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"How I can start to learn about large language models application? can you provide a roadmap in ten steps?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PWmv8H1enEx",
        "outputId": "20f309a5-14a0-444f-ab62-0f1cebe25ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: How I can start to learn about large language models application? can you provide a roadmap in ten steps?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Sure! Here's a roadmap for learning about large language models application:\n",
            "\n",
            "1. Understand the basics of natural language processing (NLP) and machine learning.\n",
            "2. Learn about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs).\n",
            "3. Familiarize yourself with popular frameworks and libraries used for building NLP applications, such as TensorFlow and PyTorch.\n",
            "4. Practice building your own NLP applications using these frameworks and libraries.\n",
            "5. Experiment with various hyperparameters to optimize your models.\n",
            "6. Evaluate your models on datasets that are relevant to your use case.\n",
            "7. Explore pre-trained models and their architectures to get inspiration for your own work.\n",
            "8. Collaborate with other developers and researchers in the field to stay up-to-date on the latest developments.\n",
            "9. Keep track of new trends and emerging technologies in the field.\n",
            "10. Continuously improve your skills by attending workshops and training sessions.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Does it requires programming skills?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7HnfbYcenH4",
        "outputId": "07b62bd3-1ace-4225-9c80-349a8ea9818b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How I can start to learn about large language models application? can you provide a roadmap in ten steps?\n",
            "AI:  Sure! Here's a roadmap for learning about large language models application:\n",
            "\n",
            "1. Understand the basics of natural language processing (NLP) and machine learning.\n",
            "2. Learn about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs).\n",
            "3. Familiarize yourself with popular frameworks and libraries used for building NLP applications, such as TensorFlow and PyTorch.\n",
            "4. Practice building your own NLP applications using these frameworks and libraries.\n",
            "5. Experiment with various hyperparameters to optimize your models.\n",
            "6. Evaluate your models on datasets that are relevant to your use case.\n",
            "7. Explore pre-trained models and their architectures to get inspiration for your own work.\n",
            "8. Collaborate with other developers and researchers in the field to stay up-to-date on the latest developments.\n",
            "9. Keep track of new trends and emerging technologies in the field.\n",
            "10. Continuously improve your skills by attending workshops and training sessions.\n",
            "User \n",
            "Human: Does it requires programming skills?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Yes, some basic knowledge of programming is required to implement NLP applications. However, there are many resources available online to help beginners learn programming skills.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What about mathematical knowledge? Does it requres?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyPPSIFAenLG",
        "outputId": "542f6f9d-68d4-4604-d6fb-caf2f3f1a64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How I can start to learn about large language models application? can you provide a roadmap in ten steps?\n",
            "AI:  Sure! Here's a roadmap for learning about large language models application:\n",
            "\n",
            "1. Understand the basics of natural language processing (NLP) and machine learning.\n",
            "2. Learn about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs).\n",
            "3. Familiarize yourself with popular frameworks and libraries used for building NLP applications, such as TensorFlow and PyTorch.\n",
            "4. Practice building your own NLP applications using these frameworks and libraries.\n",
            "5. Experiment with various hyperparameters to optimize your models.\n",
            "6. Evaluate your models on datasets that are relevant to your use case.\n",
            "7. Explore pre-trained models and their architectures to get inspiration for your own work.\n",
            "8. Collaborate with other developers and researchers in the field to stay up-to-date on the latest developments.\n",
            "9. Keep track of new trends and emerging technologies in the field.\n",
            "10. Continuously improve your skills by attending workshops and training sessions.\n",
            "User \n",
            "Human: Does it requires programming skills?\n",
            "AI:  Yes, some basic knowledge of programming is required to implement NLP applications. However, there are many resources available online to help beginners learn programming skills.\n",
            "User \n",
            "Human: What about mathematical knowledge? Does it requres?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Yes, some basic knowledge of mathematics is required to understand NLP concepts. This includes topics like linear algebra, calculus, and statistics.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Which programming language is suitable for piplining large language models?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X69MZ4OCJ6pd",
        "outputId": "80ae5aa6-16bb-40ad-c040-555e07a78845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How I can start to learn about large language models application? can you provide a roadmap in ten steps?\n",
            "AI:  Sure! Here's a roadmap for learning about large language models application:\n",
            "\n",
            "1. Understand the basics of natural language processing (NLP) and machine learning.\n",
            "2. Learn about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs).\n",
            "3. Familiarize yourself with popular frameworks and libraries used for building NLP applications, such as TensorFlow and PyTorch.\n",
            "4. Practice building your own NLP applications using these frameworks and libraries.\n",
            "5. Experiment with various hyperparameters to optimize your models.\n",
            "6. Evaluate your models on datasets that are relevant to your use case.\n",
            "7. Explore pre-trained models and their architectures to get inspiration for your own work.\n",
            "8. Collaborate with other developers and researchers in the field to stay up-to-date on the latest developments.\n",
            "9. Keep track of new trends and emerging technologies in the field.\n",
            "10. Continuously improve your skills by attending workshops and training sessions.\n",
            "User \n",
            "Human: Does it requires programming skills?\n",
            "AI:  Yes, some basic knowledge of programming is required to implement NLP applications. However, there are many resources available online to help beginners learn programming skills.\n",
            "User \n",
            "Human: What about mathematical knowledge? Does it requres?\n",
            "AI:  Yes, some basic knowledge of mathematics is required to understand NLP concepts. This includes topics like linear algebra, calculus, and statistics.\n",
            "User \n",
            "Human: Which programming language is suitable for piplining large language models?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Python and R are commonly used for NLP applications. Both languages have a wide range of libraries and tools that make them ideal for this task.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What couple of paragraphs about about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs)\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLgB3Y3NnrX_",
        "outputId": "7745243e-d4d9-4789-a578-be0e20a8ab2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How I can start to learn about large language models application? can you provide a roadmap in ten steps?\n",
            "AI:  Sure! Here's a roadmap for learning about large language models application:\n",
            "\n",
            "1. Understand the basics of natural language processing (NLP) and machine learning.\n",
            "2. Learn about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs).\n",
            "3. Familiarize yourself with popular frameworks and libraries used for building NLP applications, such as TensorFlow and PyTorch.\n",
            "4. Practice building your own NLP applications using these frameworks and libraries.\n",
            "5. Experiment with various hyperparameters to optimize your models.\n",
            "6. Evaluate your models on datasets that are relevant to your use case.\n",
            "7. Explore pre-trained models and their architectures to get inspiration for your own work.\n",
            "8. Collaborate with other developers and researchers in the field to stay up-to-date on the latest developments.\n",
            "9. Keep track of new trends and emerging technologies in the field.\n",
            "10. Continuously improve your skills by attending workshops and training sessions.\n",
            "User \n",
            "Human: Does it requires programming skills?\n",
            "AI:  Yes, some basic knowledge of programming is required to implement NLP applications. However, there are many resources available online to help beginners learn programming skills.\n",
            "User \n",
            "Human: What about mathematical knowledge? Does it requres?\n",
            "AI:  Yes, some basic knowledge of mathematics is required to understand NLP concepts. This includes topics like linear algebra, calculus, and statistics.\n",
            "User \n",
            "Human: Which programming language is suitable for piplining large language models?\n",
            "AI:  Python and R are commonly used for NLP applications. Both languages have a wide range of libraries and tools that make them ideal for this task.\n",
            "User \n",
            "Human:\n",
            "Human: What couple of paragraphs about about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs)\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "  Recurrent Neural Networks (RNNs) are a type of deep learning architecture that is often used for natural language processing tasks. They are designed to process sequential data, such as text or speech, and are particularly effective for tasks like language translation and summarization. Convolutional Neural Networks (CNNs) are another type of deep learning architecture that is often used for natural language processing tasks. Unlike RNNs, CNNs are designed to process spatial data, such as images, and are often used for tasks like image classification and segmentation.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" write two paragraphs about Understand the basics of natural language processing (NLP) and machine learning\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJd0MUEic4nz",
        "outputId": "b3702ce3-58ed-4576-da6d-8b5a59f3f52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How I can start to learn about large language models application? can you provide a roadmap in ten steps?\n",
            "AI:  Sure! Here's a roadmap for learning about large language models application:\n",
            "\n",
            "1. Understand the basics of natural language processing (NLP) and machine learning.\n",
            "2. Learn about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs).\n",
            "3. Familiarize yourself with popular frameworks and libraries used for building NLP applications, such as TensorFlow and PyTorch.\n",
            "4. Practice building your own NLP applications using these frameworks and libraries.\n",
            "5. Experiment with various hyperparameters to optimize your models.\n",
            "6. Evaluate your models on datasets that are relevant to your use case.\n",
            "7. Explore pre-trained models and their architectures to get inspiration for your own work.\n",
            "8. Collaborate with other developers and researchers in the field to stay up-to-date on the latest developments.\n",
            "9. Keep track of new trends and emerging technologies in the field.\n",
            "10. Continuously improve your skills by attending workshops and training sessions.\n",
            "User \n",
            "Human: Does it requires programming skills?\n",
            "AI:  Yes, some basic knowledge of programming is required to implement NLP applications. However, there are many resources available online to help beginners learn programming skills.\n",
            "User \n",
            "Human: What about mathematical knowledge? Does it requres?\n",
            "AI:  Yes, some basic knowledge of mathematics is required to understand NLP concepts. This includes topics like linear algebra, calculus, and statistics.\n",
            "User \n",
            "Human: Which programming language is suitable for piplining large language models?\n",
            "AI:  Python and R are commonly used for NLP applications. Both languages have a wide range of libraries and tools that make them ideal for this task.\n",
            "User \n",
            "Human:\n",
            "Human: What couple of paragraphs about about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs)\n",
            "AI:   Recurrent Neural Networks (RNNs) are a type of deep learning architecture that is often used for natural language processing tasks. They are designed to process sequential data, such as text or speech, and are particularly effective for tasks like language translation and summarization. Convolutional Neural Networks (CNNs) are another type of deep learning architecture that is often used for natural language processing tasks. Unlike RNNs, CNNs are designed to process spatial data, such as images, and are often used for tasks like image classification and segmentation.\n",
            "User \n",
            "Human:\n",
            "Human:  write two paragraphs about Understand the basics of natural language processing (NLP) and machine learning\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) that focuses on understanding and interpreting human language. It involves analyzing and recognizing patterns in language, which can be used to perform tasks such as sentiment analysis, information extraction, and dialogue systems. Machine Learning is a subset of AI that involves algorithms that can learn from data and improve their performance over time. It is used to build predictive models that can be used to make predictions about future events. In order to understand NLP and machine learning, one must first understand the fundamentals of AI, including supervised and unsupervised learning, feature engineering, and model evaluation.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What is the main activity of banks?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Oln_en-hU3O",
        "outputId": "b459fcbb-9ea7-4a4e-a8f7-32f2dd77219d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How I can start to learn about large language models application? can you provide a roadmap in ten steps?\n",
            "AI:  Sure! Here's a roadmap for learning about large language models application:\n",
            "\n",
            "1. Understand the basics of natural language processing (NLP) and machine learning.\n",
            "2. Learn about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs).\n",
            "3. Familiarize yourself with popular frameworks and libraries used for building NLP applications, such as TensorFlow and PyTorch.\n",
            "4. Practice building your own NLP applications using these frameworks and libraries.\n",
            "5. Experiment with various hyperparameters to optimize your models.\n",
            "6. Evaluate your models on datasets that are relevant to your use case.\n",
            "7. Explore pre-trained models and their architectures to get inspiration for your own work.\n",
            "8. Collaborate with other developers and researchers in the field to stay up-to-date on the latest developments.\n",
            "9. Keep track of new trends and emerging technologies in the field.\n",
            "10. Continuously improve your skills by attending workshops and training sessions.\n",
            "User \n",
            "Human: Does it requires programming skills?\n",
            "AI:  Yes, some basic knowledge of programming is required to implement NLP applications. However, there are many resources available online to help beginners learn programming skills.\n",
            "User \n",
            "Human: What about mathematical knowledge? Does it requres?\n",
            "AI:  Yes, some basic knowledge of mathematics is required to understand NLP concepts. This includes topics like linear algebra, calculus, and statistics.\n",
            "User \n",
            "Human: Which programming language is suitable for piplining large language models?\n",
            "AI:  Python and R are commonly used for NLP applications. Both languages have a wide range of libraries and tools that make them ideal for this task.\n",
            "User \n",
            "Human:\n",
            "Human: What couple of paragraphs about about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs)\n",
            "AI:   Recurrent Neural Networks (RNNs) are a type of deep learning architecture that is often used for natural language processing tasks. They are designed to process sequential data, such as text or speech, and are particularly effective for tasks like language translation and summarization. Convolutional Neural Networks (CNNs) are another type of deep learning architecture that is often used for natural language processing tasks. Unlike RNNs, CNNs are designed to process spatial data, such as images, and are often used for tasks like image classification and segmentation.\n",
            "User \n",
            "Human:\n",
            "Human:  write two paragraphs about Understand the basics of natural language processing (NLP) and machine learning\n",
            "AI:  Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) that focuses on understanding and interpreting human language. It involves analyzing and recognizing patterns in language, which can be used to perform tasks such as sentiment analysis, information extraction, and dialogue systems. Machine Learning is a subset of AI that involves algorithms that can learn from data and improve their performance over time. It is used to build predictive models that can be used to make predictions about future events. In order to understand NLP and machine learning, one must first understand the fundamentals of AI, including supervised and unsupervised learning, feature engineering, and model evaluation.\n",
            "User \n",
            "Human: What is the main activity of banks?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Banks typically handle financial transactions, such as accepting deposits and withdrawals, issuing loans, and providing investment services. They also offer additional services such as credit cards, debit cards, and checking accounts.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"How banks manges their portfolio through high interst rate periods?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "1Bw2KpaFhU6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc838e69-bd45-4480-b498-b9b56c1ccb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Does it requires programming skills?\n",
            "AI:  Yes, some basic knowledge of programming is required to implement NLP applications. However, there are many resources available online to help beginners learn programming skills.\n",
            "User \n",
            "Human: What about mathematical knowledge? Does it requres?\n",
            "AI:  Yes, some basic knowledge of mathematics is required to understand NLP concepts. This includes topics like linear algebra, calculus, and statistics.\n",
            "User \n",
            "Human: Which programming language is suitable for piplining large language models?\n",
            "AI:  Python and R are commonly used for NLP applications. Both languages have a wide range of libraries and tools that make them ideal for this task.\n",
            "User \n",
            "Human:\n",
            "Human: What couple of paragraphs about about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs)\n",
            "AI:   Recurrent Neural Networks (RNNs) are a type of deep learning architecture that is often used for natural language processing tasks. They are designed to process sequential data, such as text or speech, and are particularly effective for tasks like language translation and summarization. Convolutional Neural Networks (CNNs) are another type of deep learning architecture that is often used for natural language processing tasks. Unlike RNNs, CNNs are designed to process spatial data, such as images, and are often used for tasks like image classification and segmentation.\n",
            "User \n",
            "Human:\n",
            "Human:  write two paragraphs about Understand the basics of natural language processing (NLP) and machine learning\n",
            "AI:  Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) that focuses on understanding and interpreting human language. It involves analyzing and recognizing patterns in language, which can be used to perform tasks such as sentiment analysis, information extraction, and dialogue systems. Machine Learning is a subset of AI that involves algorithms that can learn from data and improve their performance over time. It is used to build predictive models that can be used to make predictions about future events. In order to understand NLP and machine learning, one must first understand the fundamentals of AI, including supervised and unsupervised learning, feature engineering, and model evaluation.\n",
            "User \n",
            "Human: What is the main activity of banks?\n",
            "AI:  Banks typically handle financial transactions, such as accepting deposits and withdrawals, issuing loans, and providing investment services. They also offer additional services such as credit cards, debit cards, and checking accounts.\n",
            "User \n",
            "Human:\n",
            "Human: How banks manges their portfolio through high interst rate periods?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "  Banks typically manage their portfolio by investing in assets that generate higher returns than the cost of borrowing money. These assets include government bonds, stocks, and other investments that provide long-term value to the bank. During high interest rate periods, banks may invest in short-term assets such as Treasury bills or commercial paper to generate higher returns. Additionally, banks may use derivatives such as futures or options to hedge against risk and lock in profits.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What are the similiarities and differences of trading book and banking book portfolios in banks?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh1dTVPFLEXC",
        "outputId": "553da5f0-5e70-4f69-a5ef-086840875739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What about mathematical knowledge? Does it requres?\n",
            "AI:  Yes, some basic knowledge of mathematics is required to understand NLP concepts. This includes topics like linear algebra, calculus, and statistics.\n",
            "User \n",
            "Human: Which programming language is suitable for piplining large language models?\n",
            "AI:  Python and R are commonly used for NLP applications. Both languages have a wide range of libraries and tools that make them ideal for this task.\n",
            "User \n",
            "Human:\n",
            "Human: What couple of paragraphs about about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs)\n",
            "AI:   Recurrent Neural Networks (RNNs) are a type of deep learning architecture that is often used for natural language processing tasks. They are designed to process sequential data, such as text or speech, and are particularly effective for tasks like language translation and summarization. Convolutional Neural Networks (CNNs) are another type of deep learning architecture that is often used for natural language processing tasks. Unlike RNNs, CNNs are designed to process spatial data, such as images, and are often used for tasks like image classification and segmentation.\n",
            "User \n",
            "Human:\n",
            "Human:  write two paragraphs about Understand the basics of natural language processing (NLP) and machine learning\n",
            "AI:  Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) that focuses on understanding and interpreting human language. It involves analyzing and recognizing patterns in language, which can be used to perform tasks such as sentiment analysis, information extraction, and dialogue systems. Machine Learning is a subset of AI that involves algorithms that can learn from data and improve their performance over time. It is used to build predictive models that can be used to make predictions about future events. In order to understand NLP and machine learning, one must first understand the fundamentals of AI, including supervised and unsupervised learning, feature engineering, and model evaluation.\n",
            "User \n",
            "Human: What is the main activity of banks?\n",
            "AI:  Banks typically handle financial transactions, such as accepting deposits and withdrawals, issuing loans, and providing investment services. They also offer additional services such as credit cards, debit cards, and checking accounts.\n",
            "User \n",
            "Human:\n",
            "Human: How banks manges their portfolio through high interst rate periods?\n",
            "AI:   Banks typically manage their portfolio by investing in assets that generate higher returns than the cost of borrowing money. These assets include government bonds, stocks, and other investments that provide long-term value to the bank. During high interest rate periods, banks may invest in short-term assets such as Treasury bills or commercial paper to generate higher returns. Additionally, banks may use derivatives such as futures or options to hedge against risk and lock in profits.\n",
            "User \n",
            "Human:\n",
            "Human: What are the similiarities and differences of trading book and banking book portfolios in banks?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "  The trading book and banking book portfolios in banks are similar in that they both involve managing assets and liabilities. However, the trading book is focused on generating income from trading securities, while the banking book is focused on lending money and managing customer deposits. Additionally, the trading book is usually more volatile than the banking book due to the nature of the assets involved.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Can you summarize the type of models used in trading book and banking book for the capital requirement calculation?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAqiKiriLoEy",
        "outputId": "f71f864a-9563-4bf3-d2b6-45f11173c422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Which programming language is suitable for piplining large language models?\n",
            "AI:  Python and R are commonly used for NLP applications. Both languages have a wide range of libraries and tools that make them ideal for this task.\n",
            "User \n",
            "Human:\n",
            "Human: What couple of paragraphs about about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs)\n",
            "AI:   Recurrent Neural Networks (RNNs) are a type of deep learning architecture that is often used for natural language processing tasks. They are designed to process sequential data, such as text or speech, and are particularly effective for tasks like language translation and summarization. Convolutional Neural Networks (CNNs) are another type of deep learning architecture that is often used for natural language processing tasks. Unlike RNNs, CNNs are designed to process spatial data, such as images, and are often used for tasks like image classification and segmentation.\n",
            "User \n",
            "Human:\n",
            "Human:  write two paragraphs about Understand the basics of natural language processing (NLP) and machine learning\n",
            "AI:  Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) that focuses on understanding and interpreting human language. It involves analyzing and recognizing patterns in language, which can be used to perform tasks such as sentiment analysis, information extraction, and dialogue systems. Machine Learning is a subset of AI that involves algorithms that can learn from data and improve their performance over time. It is used to build predictive models that can be used to make predictions about future events. In order to understand NLP and machine learning, one must first understand the fundamentals of AI, including supervised and unsupervised learning, feature engineering, and model evaluation.\n",
            "User \n",
            "Human: What is the main activity of banks?\n",
            "AI:  Banks typically handle financial transactions, such as accepting deposits and withdrawals, issuing loans, and providing investment services. They also offer additional services such as credit cards, debit cards, and checking accounts.\n",
            "User \n",
            "Human:\n",
            "Human: How banks manges their portfolio through high interst rate periods?\n",
            "AI:   Banks typically manage their portfolio by investing in assets that generate higher returns than the cost of borrowing money. These assets include government bonds, stocks, and other investments that provide long-term value to the bank. During high interest rate periods, banks may invest in short-term assets such as Treasury bills or commercial paper to generate higher returns. Additionally, banks may use derivatives such as futures or options to hedge against risk and lock in profits.\n",
            "User \n",
            "Human:\n",
            "Human: What are the similiarities and differences of trading book and banking book portfolios in banks?\n",
            "AI:   The trading book and banking book portfolios in banks are similar in that they both involve managing assets and liabilities. However, the trading book is focused on generating income from trading securities, while the banking book is focused on lending money and managing customer deposits. Additionally, the trading book is usually more volatile than the banking book due to the nature of the assets involved.\n",
            "User \n",
            "Human:\n",
            "Human: Can you summarize the type of models used in trading book and banking book for the capital requirement calculation?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "   In the banking industry, the capital requirement calculation is typically based on Basel III regulations, which require banks to maintain a certain level of equity capital and liquidity ratios. This is done by calculating the Tier 1 Capital ratio, which is the amount of equity capital required to support the bank's total assets. For the trading book, the capital requirement calculation is typically based on market risks and volatility, which can be modeled using Monte Carlo simulations or historical data analysis.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Probability of defauld, loss given default and exposure at default, are three main component in capital calculation. Write a paragraph summary about each of them.\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOWW88H8MO7V",
        "outputId": "baf267ae-d782-4430-853d-798e7e24ace7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What couple of paragraphs about about different types of language models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs)\n",
            "AI:   Recurrent Neural Networks (RNNs) are a type of deep learning architecture that is often used for natural language processing tasks. They are designed to process sequential data, such as text or speech, and are particularly effective for tasks like language translation and summarization. Convolutional Neural Networks (CNNs) are another type of deep learning architecture that is often used for natural language processing tasks. Unlike RNNs, CNNs are designed to process spatial data, such as images, and are often used for tasks like image classification and segmentation.\n",
            "User \n",
            "Human:\n",
            "Human:  write two paragraphs about Understand the basics of natural language processing (NLP) and machine learning\n",
            "AI:  Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) that focuses on understanding and interpreting human language. It involves analyzing and recognizing patterns in language, which can be used to perform tasks such as sentiment analysis, information extraction, and dialogue systems. Machine Learning is a subset of AI that involves algorithms that can learn from data and improve their performance over time. It is used to build predictive models that can be used to make predictions about future events. In order to understand NLP and machine learning, one must first understand the fundamentals of AI, including supervised and unsupervised learning, feature engineering, and model evaluation.\n",
            "User \n",
            "Human: What is the main activity of banks?\n",
            "AI:  Banks typically handle financial transactions, such as accepting deposits and withdrawals, issuing loans, and providing investment services. They also offer additional services such as credit cards, debit cards, and checking accounts.\n",
            "User \n",
            "Human:\n",
            "Human: How banks manges their portfolio through high interst rate periods?\n",
            "AI:   Banks typically manage their portfolio by investing in assets that generate higher returns than the cost of borrowing money. These assets include government bonds, stocks, and other investments that provide long-term value to the bank. During high interest rate periods, banks may invest in short-term assets such as Treasury bills or commercial paper to generate higher returns. Additionally, banks may use derivatives such as futures or options to hedge against risk and lock in profits.\n",
            "User \n",
            "Human:\n",
            "Human: What are the similiarities and differences of trading book and banking book portfolios in banks?\n",
            "AI:   The trading book and banking book portfolios in banks are similar in that they both involve managing assets and liabilities. However, the trading book is focused on generating income from trading securities, while the banking book is focused on lending money and managing customer deposits. Additionally, the trading book is usually more volatile than the banking book due to the nature of the assets involved.\n",
            "User \n",
            "Human:\n",
            "Human: Can you summarize the type of models used in trading book and banking book for the capital requirement calculation?\n",
            "AI:    In the banking industry, the capital requirement calculation is typically based on Basel III regulations, which require banks to maintain a certain level of equity capital and liquidity ratios. This is done by calculating the Tier 1 Capital ratio, which is the amount of equity capital required to support the bank's total assets. For the trading book, the capital requirement calculation is typically based on market risks and volatility, which can be modeled using Monte Carlo simulations or historical data analysis.\n",
            "User \n",
            "Human: Probability of defauld, loss given default and exposure at default, are three main component in capital calculation. Write a paragraph summary about each of them.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "  The probability of default is the likelihood that a borrower will fail to repay a loan. Loss Given Default (LGD) is the potential loss that a lender could experience if a borrower defaults on a loan. Exposure at Default (EAD) is the amount of a borrower's assets that could potentially be seized by a creditor in case of default. These three components are used to calculate the overall risk associated with a borrower and determine the appropriate level of capital that should be maintained by the bank.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"How banks do hedging against market risk?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "4BG8tXIlhU9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94580593-2c94-4ae3-bbc9-72dbd1a7ddd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human:  write two paragraphs about Understand the basics of natural language processing (NLP) and machine learning\n",
            "AI:  Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) that focuses on understanding and interpreting human language. It involves analyzing and recognizing patterns in language, which can be used to perform tasks such as sentiment analysis, information extraction, and dialogue systems. Machine Learning is a subset of AI that involves algorithms that can learn from data and improve their performance over time. It is used to build predictive models that can be used to make predictions about future events. In order to understand NLP and machine learning, one must first understand the fundamentals of AI, including supervised and unsupervised learning, feature engineering, and model evaluation.\n",
            "User \n",
            "Human: What is the main activity of banks?\n",
            "AI:  Banks typically handle financial transactions, such as accepting deposits and withdrawals, issuing loans, and providing investment services. They also offer additional services such as credit cards, debit cards, and checking accounts.\n",
            "User \n",
            "Human:\n",
            "Human: How banks manges their portfolio through high interst rate periods?\n",
            "AI:   Banks typically manage their portfolio by investing in assets that generate higher returns than the cost of borrowing money. These assets include government bonds, stocks, and other investments that provide long-term value to the bank. During high interest rate periods, banks may invest in short-term assets such as Treasury bills or commercial paper to generate higher returns. Additionally, banks may use derivatives such as futures or options to hedge against risk and lock in profits.\n",
            "User \n",
            "Human:\n",
            "Human: What are the similiarities and differences of trading book and banking book portfolios in banks?\n",
            "AI:   The trading book and banking book portfolios in banks are similar in that they both involve managing assets and liabilities. However, the trading book is focused on generating income from trading securities, while the banking book is focused on lending money and managing customer deposits. Additionally, the trading book is usually more volatile than the banking book due to the nature of the assets involved.\n",
            "User \n",
            "Human:\n",
            "Human: Can you summarize the type of models used in trading book and banking book for the capital requirement calculation?\n",
            "AI:    In the banking industry, the capital requirement calculation is typically based on Basel III regulations, which require banks to maintain a certain level of equity capital and liquidity ratios. This is done by calculating the Tier 1 Capital ratio, which is the amount of equity capital required to support the bank's total assets. For the trading book, the capital requirement calculation is typically based on market risks and volatility, which can be modeled using Monte Carlo simulations or historical data analysis.\n",
            "User \n",
            "Human: Probability of defauld, loss given default and exposure at default, are three main component in capital calculation. Write a paragraph summary about each of them.\n",
            "AI:   The probability of default is the likelihood that a borrower will fail to repay a loan. Loss Given Default (LGD) is the potential loss that a lender could experience if a borrower defaults on a loan. Exposure at Default (EAD) is the amount of a borrower's assets that could potentially be seized by a creditor in case of default. These three components are used to calculate the overall risk associated with a borrower and determine the appropriate level of capital that should be maintained by the bank.\n",
            "User \n",
            "Human: How banks do hedging against market risk?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "  Banks can hedge against market risk by taking positions in the foreign exchange market, buying and selling derivatives, and engaging in forward contracts. Foreign exchange markets allow banks to buy and sell currencies to protect themselves from fluctuations in currency values. Derivatives are financial instruments that derive their value from underlying assets such as stocks, bonds, or commodities. Forward contracts are agreements between two parties to buy and sell assets at predetermined prices and dates. By utilizing these tools, banks can reduce their exposure to market risk and increase their profitability.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What are the most important models for credit acceptance scorecard which banks use for their internal rating purposes?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "bFbgKRWchVC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f2d85e-2d8d-42a4-d047-4e825811ff3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What is the main activity of banks?\n",
            "AI:  Banks typically handle financial transactions, such as accepting deposits and withdrawals, issuing loans, and providing investment services. They also offer additional services such as credit cards, debit cards, and checking accounts.\n",
            "User \n",
            "Human:\n",
            "Human: How banks manges their portfolio through high interst rate periods?\n",
            "AI:   Banks typically manage their portfolio by investing in assets that generate higher returns than the cost of borrowing money. These assets include government bonds, stocks, and other investments that provide long-term value to the bank. During high interest rate periods, banks may invest in short-term assets such as Treasury bills or commercial paper to generate higher returns. Additionally, banks may use derivatives such as futures or options to hedge against risk and lock in profits.\n",
            "User \n",
            "Human:\n",
            "Human: What are the similiarities and differences of trading book and banking book portfolios in banks?\n",
            "AI:   The trading book and banking book portfolios in banks are similar in that they both involve managing assets and liabilities. However, the trading book is focused on generating income from trading securities, while the banking book is focused on lending money and managing customer deposits. Additionally, the trading book is usually more volatile than the banking book due to the nature of the assets involved.\n",
            "User \n",
            "Human:\n",
            "Human: Can you summarize the type of models used in trading book and banking book for the capital requirement calculation?\n",
            "AI:    In the banking industry, the capital requirement calculation is typically based on Basel III regulations, which require banks to maintain a certain level of equity capital and liquidity ratios. This is done by calculating the Tier 1 Capital ratio, which is the amount of equity capital required to support the bank's total assets. For the trading book, the capital requirement calculation is typically based on market risks and volatility, which can be modeled using Monte Carlo simulations or historical data analysis.\n",
            "User \n",
            "Human: Probability of defauld, loss given default and exposure at default, are three main component in capital calculation. Write a paragraph summary about each of them.\n",
            "AI:   The probability of default is the likelihood that a borrower will fail to repay a loan. Loss Given Default (LGD) is the potential loss that a lender could experience if a borrower defaults on a loan. Exposure at Default (EAD) is the amount of a borrower's assets that could potentially be seized by a creditor in case of default. These three components are used to calculate the overall risk associated with a borrower and determine the appropriate level of capital that should be maintained by the bank.\n",
            "User \n",
            "Human: How banks do hedging against market risk?\n",
            "AI:   Banks can hedge against market risk by taking positions in the foreign exchange market, buying and selling derivatives, and engaging in forward contracts. Foreign exchange markets allow banks to buy and sell currencies to protect themselves from fluctuations in currency values. Derivatives are financial instruments that derive their value from underlying assets such as stocks, bonds, or commodities. Forward contracts are agreements between two parties to buy and sell assets at predetermined prices and dates. By utilizing these tools, banks can reduce their exposure to market risk and increase their profitability.\n",
            "User \n",
            "Human:\n",
            "Human: What are the most important models for credit acceptance scorecard which banks use for their internal rating purposes?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "   Some of the most important models for credit acceptance scorecard include predictive analytics models, machine learning algorithms, and statistical models. These models help banks assess the risk of lending to different types of customers and make decisions on whether to approve or deny loans. The models take into account factors such as past payment history, current income, debt-to-income ratio, and employment history to determine the likelihood of repayment. These models are often built using large datasets of historical loan data and have been shown to improve accuracy in predicting future loan repayments.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Does logistic regression is used in credit ecoring models?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "kWXDZSgDhVFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b79f32-d97e-46fc-d6b4-7ce9cd95b841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How banks manges their portfolio through high interst rate periods?\n",
            "AI:   Banks typically manage their portfolio by investing in assets that generate higher returns than the cost of borrowing money. These assets include government bonds, stocks, and other investments that provide long-term value to the bank. During high interest rate periods, banks may invest in short-term assets such as Treasury bills or commercial paper to generate higher returns. Additionally, banks may use derivatives such as futures or options to hedge against risk and lock in profits.\n",
            "User \n",
            "Human:\n",
            "Human: What are the similiarities and differences of trading book and banking book portfolios in banks?\n",
            "AI:   The trading book and banking book portfolios in banks are similar in that they both involve managing assets and liabilities. However, the trading book is focused on generating income from trading securities, while the banking book is focused on lending money and managing customer deposits. Additionally, the trading book is usually more volatile than the banking book due to the nature of the assets involved.\n",
            "User \n",
            "Human:\n",
            "Human: Can you summarize the type of models used in trading book and banking book for the capital requirement calculation?\n",
            "AI:    In the banking industry, the capital requirement calculation is typically based on Basel III regulations, which require banks to maintain a certain level of equity capital and liquidity ratios. This is done by calculating the Tier 1 Capital ratio, which is the amount of equity capital required to support the bank's total assets. For the trading book, the capital requirement calculation is typically based on market risks and volatility, which can be modeled using Monte Carlo simulations or historical data analysis.\n",
            "User \n",
            "Human: Probability of defauld, loss given default and exposure at default, are three main component in capital calculation. Write a paragraph summary about each of them.\n",
            "AI:   The probability of default is the likelihood that a borrower will fail to repay a loan. Loss Given Default (LGD) is the potential loss that a lender could experience if a borrower defaults on a loan. Exposure at Default (EAD) is the amount of a borrower's assets that could potentially be seized by a creditor in case of default. These three components are used to calculate the overall risk associated with a borrower and determine the appropriate level of capital that should be maintained by the bank.\n",
            "User \n",
            "Human: How banks do hedging against market risk?\n",
            "AI:   Banks can hedge against market risk by taking positions in the foreign exchange market, buying and selling derivatives, and engaging in forward contracts. Foreign exchange markets allow banks to buy and sell currencies to protect themselves from fluctuations in currency values. Derivatives are financial instruments that derive their value from underlying assets such as stocks, bonds, or commodities. Forward contracts are agreements between two parties to buy and sell assets at predetermined prices and dates. By utilizing these tools, banks can reduce their exposure to market risk and increase their profitability.\n",
            "User \n",
            "Human:\n",
            "Human: What are the most important models for credit acceptance scorecard which banks use for their internal rating purposes?\n",
            "AI:    Some of the most important models for credit acceptance scorecard include predictive analytics models, machine learning algorithms, and statistical models. These models help banks assess the risk of lending to different types of customers and make decisions on whether to approve or deny loans. The models take into account factors such as past payment history, current income, debt-to-income ratio, and employment history to determine the likelihood of repayment. These models are often built using large datasets of historical loan data and have been shown to improve accuracy in predicting future loan repayments.\n",
            "User \n",
            "Human: Does logistic regression is used in credit ecoring models?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "   Yes, logistic regression is often used in credit scoring models to predict the likelihood of a borrower paying back a loan. It is a commonly used technique in the finance industry to build predictive models that can accurately identify high-risk borrowers and reject low-risk applicants. The model uses a combination of features such as age, income, occupation, and education level to generate a prediction score that can be used to determine the risk of defaulting on a loan.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Does banks use survival analysis for predicting probability of default?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "q6u4AdUthVIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d55e1b7-6efa-4c9e-a7b3-d1163e01a17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What are the similiarities and differences of trading book and banking book portfolios in banks?\n",
            "AI:   The trading book and banking book portfolios in banks are similar in that they both involve managing assets and liabilities. However, the trading book is focused on generating income from trading securities, while the banking book is focused on lending money and managing customer deposits. Additionally, the trading book is usually more volatile than the banking book due to the nature of the assets involved.\n",
            "User \n",
            "Human:\n",
            "Human: Can you summarize the type of models used in trading book and banking book for the capital requirement calculation?\n",
            "AI:    In the banking industry, the capital requirement calculation is typically based on Basel III regulations, which require banks to maintain a certain level of equity capital and liquidity ratios. This is done by calculating the Tier 1 Capital ratio, which is the amount of equity capital required to support the bank's total assets. For the trading book, the capital requirement calculation is typically based on market risks and volatility, which can be modeled using Monte Carlo simulations or historical data analysis.\n",
            "User \n",
            "Human: Probability of defauld, loss given default and exposure at default, are three main component in capital calculation. Write a paragraph summary about each of them.\n",
            "AI:   The probability of default is the likelihood that a borrower will fail to repay a loan. Loss Given Default (LGD) is the potential loss that a lender could experience if a borrower defaults on a loan. Exposure at Default (EAD) is the amount of a borrower's assets that could potentially be seized by a creditor in case of default. These three components are used to calculate the overall risk associated with a borrower and determine the appropriate level of capital that should be maintained by the bank.\n",
            "User \n",
            "Human: How banks do hedging against market risk?\n",
            "AI:   Banks can hedge against market risk by taking positions in the foreign exchange market, buying and selling derivatives, and engaging in forward contracts. Foreign exchange markets allow banks to buy and sell currencies to protect themselves from fluctuations in currency values. Derivatives are financial instruments that derive their value from underlying assets such as stocks, bonds, or commodities. Forward contracts are agreements between two parties to buy and sell assets at predetermined prices and dates. By utilizing these tools, banks can reduce their exposure to market risk and increase their profitability.\n",
            "User \n",
            "Human:\n",
            "Human: What are the most important models for credit acceptance scorecard which banks use for their internal rating purposes?\n",
            "AI:    Some of the most important models for credit acceptance scorecard include predictive analytics models, machine learning algorithms, and statistical models. These models help banks assess the risk of lending to different types of customers and make decisions on whether to approve or deny loans. The models take into account factors such as past payment history, current income, debt-to-income ratio, and employment history to determine the likelihood of repayment. These models are often built using large datasets of historical loan data and have been shown to improve accuracy in predicting future loan repayments.\n",
            "User \n",
            "Human: Does logistic regression is used in credit ecoring models?\n",
            "AI:    Yes, logistic regression is often used in credit scoring models to predict the likelihood of a borrower paying back a loan. It is a commonly used technique in the finance industry to build predictive models that can accurately identify high-risk borrowers and reject low-risk applicants. The model uses a combination of features such as age, income, occupation, and education level to generate a prediction score that can be used to determine the risk of defaulting on a loan.\n",
            "User \n",
            "Human:\n",
            "Human: Does banks use survival analysis for predicting probability of default?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "    Yes, survival analysis is often used in the banking industry to predict the likelihood of a borrower defaulting on a loan. It is a common method used to analyze time series data and can be used to identify patterns in loan delinquency rates. Survival analysis takes into account variables such as the length of time since the last payment, the number of payments made, and other factors to determine the likelihood of default. The results of the analysis can be used to develop predictive models that can accurately identify high-risk borrowers and reject low-risk applicants.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What is the main responsibilities of basell comittee on banking?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "H0A3e8tzhVLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699a5322-9b91-435f-f095-8f97a0833f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Can you summarize the type of models used in trading book and banking book for the capital requirement calculation?\n",
            "AI:    In the banking industry, the capital requirement calculation is typically based on Basel III regulations, which require banks to maintain a certain level of equity capital and liquidity ratios. This is done by calculating the Tier 1 Capital ratio, which is the amount of equity capital required to support the bank's total assets. For the trading book, the capital requirement calculation is typically based on market risks and volatility, which can be modeled using Monte Carlo simulations or historical data analysis.\n",
            "User \n",
            "Human: Probability of defauld, loss given default and exposure at default, are three main component in capital calculation. Write a paragraph summary about each of them.\n",
            "AI:   The probability of default is the likelihood that a borrower will fail to repay a loan. Loss Given Default (LGD) is the potential loss that a lender could experience if a borrower defaults on a loan. Exposure at Default (EAD) is the amount of a borrower's assets that could potentially be seized by a creditor in case of default. These three components are used to calculate the overall risk associated with a borrower and determine the appropriate level of capital that should be maintained by the bank.\n",
            "User \n",
            "Human: How banks do hedging against market risk?\n",
            "AI:   Banks can hedge against market risk by taking positions in the foreign exchange market, buying and selling derivatives, and engaging in forward contracts. Foreign exchange markets allow banks to buy and sell currencies to protect themselves from fluctuations in currency values. Derivatives are financial instruments that derive their value from underlying assets such as stocks, bonds, or commodities. Forward contracts are agreements between two parties to buy and sell assets at predetermined prices and dates. By utilizing these tools, banks can reduce their exposure to market risk and increase their profitability.\n",
            "User \n",
            "Human:\n",
            "Human: What are the most important models for credit acceptance scorecard which banks use for their internal rating purposes?\n",
            "AI:    Some of the most important models for credit acceptance scorecard include predictive analytics models, machine learning algorithms, and statistical models. These models help banks assess the risk of lending to different types of customers and make decisions on whether to approve or deny loans. The models take into account factors such as past payment history, current income, debt-to-income ratio, and employment history to determine the likelihood of repayment. These models are often built using large datasets of historical loan data and have been shown to improve accuracy in predicting future loan repayments.\n",
            "User \n",
            "Human: Does logistic regression is used in credit ecoring models?\n",
            "AI:    Yes, logistic regression is often used in credit scoring models to predict the likelihood of a borrower paying back a loan. It is a commonly used technique in the finance industry to build predictive models that can accurately identify high-risk borrowers and reject low-risk applicants. The model uses a combination of features such as age, income, occupation, and education level to generate a prediction score that can be used to determine the risk of defaulting on a loan.\n",
            "User \n",
            "Human:\n",
            "Human: Does banks use survival analysis for predicting probability of default?\n",
            "AI:     Yes, survival analysis is often used in the banking industry to predict the likelihood of a borrower defaulting on a loan. It is a common method used to analyze time series data and can be used to identify patterns in loan delinquency rates. Survival analysis takes into account variables such as the length of time since the last payment, the number of payments made, and other factors to determine the likelihood of default. The results of the analysis can be used to develop predictive models that can accurately identify high-risk borrowers and reject low-risk applicants.\n",
            "User \n",
            "Human: What is the main responsibilities of basell comittee on banking?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "    The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"summarize the main responsibilites of Basel committee in five seperate paragraphs.\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "5vX6u1uPhVOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6012ee70-2f78-4eab-9d75-65fa82e9a6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How banks do hedging against market risk?\n",
            "AI:   Banks can hedge against market risk by taking positions in the foreign exchange market, buying and selling derivatives, and engaging in forward contracts. Foreign exchange markets allow banks to buy and sell currencies to protect themselves from fluctuations in currency values. Derivatives are financial instruments that derive their value from underlying assets such as stocks, bonds, or commodities. Forward contracts are agreements between two parties to buy and sell assets at predetermined prices and dates. By utilizing these tools, banks can reduce their exposure to market risk and increase their profitability.\n",
            "User \n",
            "Human:\n",
            "Human: What are the most important models for credit acceptance scorecard which banks use for their internal rating purposes?\n",
            "AI:    Some of the most important models for credit acceptance scorecard include predictive analytics models, machine learning algorithms, and statistical models. These models help banks assess the risk of lending to different types of customers and make decisions on whether to approve or deny loans. The models take into account factors such as past payment history, current income, debt-to-income ratio, and employment history to determine the likelihood of repayment. These models are often built using large datasets of historical loan data and have been shown to improve accuracy in predicting future loan repayments.\n",
            "User \n",
            "Human: Does logistic regression is used in credit ecoring models?\n",
            "AI:    Yes, logistic regression is often used in credit scoring models to predict the likelihood of a borrower paying back a loan. It is a commonly used technique in the finance industry to build predictive models that can accurately identify high-risk borrowers and reject low-risk applicants. The model uses a combination of features such as age, income, occupation, and education level to generate a prediction score that can be used to determine the risk of defaulting on a loan.\n",
            "User \n",
            "Human:\n",
            "Human: Does banks use survival analysis for predicting probability of default?\n",
            "AI:     Yes, survival analysis is often used in the banking industry to predict the likelihood of a borrower defaulting on a loan. It is a common method used to analyze time series data and can be used to identify patterns in loan delinquency rates. Survival analysis takes into account variables such as the length of time since the last payment, the number of payments made, and other factors to determine the likelihood of default. The results of the analysis can be used to develop predictive models that can accurately identify high-risk borrowers and reject low-risk applicants.\n",
            "User \n",
            "Human: What is the main responsibilities of basell comittee on banking?\n",
            "AI:     The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human: Write five pargraphs to describe the main responsibilites of Basel committee\n",
            "AI:      The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n",
            "Human: summarize the main responsibilites of Basel committee in five seperate paragraphs.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "      The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What are those 5 main factors which banks has to consider in bulding model taxonomy?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p09Zd4EdQgKT",
        "outputId": "2a55d867-83ac-42d5-82e9-3c3c8466409e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Does banks use survival analysis for predicting probability of default?\n",
            "AI:     Yes, survival analysis is often used in the banking industry to predict the likelihood of a borrower defaulting on a loan. It is a common method used to analyze time series data and can be used to identify patterns in loan delinquency rates. Survival analysis takes into account variables such as the length of time since the last payment, the number of payments made, and other factors to determine the likelihood of default. The results of the analysis can be used to develop predictive models that can accurately identify high-risk borrowers and reject low-risk applicants.\n",
            "User \n",
            "Human: What is the main responsibilities of basell comittee on banking?\n",
            "AI:     The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human: Write five pargraphs to describe the main responsibilites of Basel committee\n",
            "AI:      The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n",
            "Human: summarize the main responsibilites of Basel committee in five seperate paragraphs.\n",
            "AI:       The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n",
            "Human: What are those main factors which banks has to consider in bulding model taxonomy? write them in 10 bullet points.\n",
            "AI:      The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: How europian central bank supervises the banks in euro zone?\n",
            "AI:       The European Central Bank (ECB) supervises the banks in the Eurozone by setting minimum requirements for banks to meet in order to remain eligible for ECB funding. These requirements include having sufficient capital, maintaining adequate liquidity ratios, and complying with regulations such as anti-money laundering and counterfeiting laws. In addition, the ECB regularly checks the financial health of banks and may impose restrictions or penalties if necessary.\n",
            "User \n",
            "Human:\n",
            "Human: What are those 5 main factors which banks has to consider in bulding model taxonomy?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "      The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"How europian central bank supervises the banks in euro zone?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "yUGysPquhVQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8219f0-5515-4db4-8b39-fa824f3ad912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Does logistic regression is used in credit ecoring models?\n",
            "AI:    Yes, logistic regression is often used in credit scoring models to predict the likelihood of a borrower paying back a loan. It is a commonly used technique in the finance industry to build predictive models that can accurately identify high-risk borrowers and reject low-risk applicants. The model uses a combination of features such as age, income, occupation, and education level to generate a prediction score that can be used to determine the risk of defaulting on a loan.\n",
            "User \n",
            "Human:\n",
            "Human: Does banks use survival analysis for predicting probability of default?\n",
            "AI:     Yes, survival analysis is often used in the banking industry to predict the likelihood of a borrower defaulting on a loan. It is a common method used to analyze time series data and can be used to identify patterns in loan delinquency rates. Survival analysis takes into account variables such as the length of time since the last payment, the number of payments made, and other factors to determine the likelihood of default. The results of the analysis can be used to develop predictive models that can accurately identify high-risk borrowers and reject low-risk applicants.\n",
            "User \n",
            "Human: What is the main responsibilities of basell comittee on banking?\n",
            "AI:     The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human: Write five pargraphs to describe the main responsibilites of Basel committee\n",
            "AI:      The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n",
            "Human: summarize the main responsibilites of Basel committee in five seperate paragraphs.\n",
            "AI:       The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n",
            "Human: What are those main factors which banks has to consider in bulding model taxonomy? write them in 10 bullet points.\n",
            "AI:      The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: How europian central bank supervises the banks in euro zone?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "      The European Central Bank (ECB) supervises the banks in the Eurozone by setting minimum requirements for banks to meet in order to remain eligible for ECB funding. These requirements include having sufficient capital, maintaining adequate liquidity ratios, and complying with regulations such as anti-money laundering and counterfeiting laws. In addition, the ECB regularly checks the financial health of banks and may impose restrictions or penalties if necessary.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Write precise and consise email to my manage and ask her to attend our next quarterly meeting. Note that, her name is Melike.\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "hq_osheYhVT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c93b13-0c36-4517-ac66-2bdc588784ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What is the main responsibilities of basell comittee on banking?\n",
            "AI:     The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human: Write five pargraphs to describe the main responsibilites of Basel committee\n",
            "AI:      The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n",
            "Human: summarize the main responsibilites of Basel committee in five seperate paragraphs.\n",
            "AI:       The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n",
            "Human: What are those main factors which banks has to consider in bulding model taxonomy? write them in 10 bullet points.\n",
            "AI:      The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: How europian central bank supervises the banks in euro zone?\n",
            "AI:       The European Central Bank (ECB) supervises the banks in the Eurozone by setting minimum requirements for banks to meet in order to remain eligible for ECB funding. These requirements include having sufficient capital, maintaining adequate liquidity ratios, and complying with regulations such as anti-money laundering and counterfeiting laws. In addition, the ECB regularly checks the financial health of banks and may impose restrictions or penalties if necessary.\n",
            "User \n",
            "Human:\n",
            "Human: What are those 5 main factors which banks has to consider in bulding model taxonomy?\n",
            "AI:       The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: Write precise and consise email to my manage and ask her to attend our next quarterly meeting. Note that, her name is Melike.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "       Dear Melike, \n",
            "\n",
            "I am writing to request your attendance at our upcoming quarterly meeting. This important event will take place on October 15th, 2021, at 2pm. Your presence is essential to help us move forward with our goals and objectives. \n",
            "\n",
            "I look forward to seeing you there. \n",
            "\n",
            "Best regards, \n",
            "[Your Name]\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"How I can travel from Rotterdam to New York? what are the possibilities?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "A8dZ43l0hVZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c6a140-5ac0-40d1-a288-67a0808d1eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Write five pargraphs to describe the main responsibilites of Basel committee\n",
            "AI:      The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n",
            "Human: summarize the main responsibilites of Basel committee in five seperate paragraphs.\n",
            "AI:       The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n",
            "Human: What are those main factors which banks has to consider in bulding model taxonomy? write them in 10 bullet points.\n",
            "AI:      The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: How europian central bank supervises the banks in euro zone?\n",
            "AI:       The European Central Bank (ECB) supervises the banks in the Eurozone by setting minimum requirements for banks to meet in order to remain eligible for ECB funding. These requirements include having sufficient capital, maintaining adequate liquidity ratios, and complying with regulations such as anti-money laundering and counterfeiting laws. In addition, the ECB regularly checks the financial health of banks and may impose restrictions or penalties if necessary.\n",
            "User \n",
            "Human:\n",
            "Human: What are those 5 main factors which banks has to consider in bulding model taxonomy?\n",
            "AI:       The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: Write precise and consise email to my manage and ask her to attend our next quarterly meeting. Note that, her name is Melike.\n",
            "AI:        Dear Melike, \n",
            "\n",
            "I am writing to request your attendance at our upcoming quarterly meeting. This important event will take place on October 15th, 2021, at 2pm. Your presence is essential to help us move forward with our goals and objectives. \n",
            "\n",
            "I look forward to seeing you there. \n",
            "\n",
            "Best regards, \n",
            "[Your Name]\n",
            "User \n",
            "Human: How I can travel from Rotterdam to New York? what are the possibilities?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "       There are several options available for traveling from Rotterdam to New York, including flights, trains, and buses. Flights are offered by various airlines, including KLM Royal Dutch Airlines, Air France, and Delta. Train tickets can be purchased through the Netherlands Railways website. Buses can be booked through websites like FlixBus or Greyhound. It is recommended to book in advance to secure the best prices and availability.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What are unique features of Dutch which other languages do not have them?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "Yr5-hmNchVcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70cef165-0d5d-46a2-cef7-3fcc746d209e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: summarize the main responsibilites of Basel committee in five seperate paragraphs.\n",
            "AI:       The Basel Committee on Banking Supervision is responsible for developing guidelines and standards for the global banking industry. Its main responsibilities include ensuring that banks maintain adequate levels of capital, assessing the soundness of individual institutions, and monitoring systemic risks in the banking sector. The committee also sets out rules and requirements for banks to follow when they issue new products and services, including consumer and business accounts. Additionally, the committee works to ensure that banks comply with international regulatory standards and best practices.\n",
            "User \n",
            "Human:\n",
            "Human: What are those main factors which banks has to consider in bulding model taxonomy? write them in 10 bullet points.\n",
            "AI:      The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: How europian central bank supervises the banks in euro zone?\n",
            "AI:       The European Central Bank (ECB) supervises the banks in the Eurozone by setting minimum requirements for banks to meet in order to remain eligible for ECB funding. These requirements include having sufficient capital, maintaining adequate liquidity ratios, and complying with regulations such as anti-money laundering and counterfeiting laws. In addition, the ECB regularly checks the financial health of banks and may impose restrictions or penalties if necessary.\n",
            "User \n",
            "Human:\n",
            "Human: What are those 5 main factors which banks has to consider in bulding model taxonomy?\n",
            "AI:       The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: Write precise and consise email to my manage and ask her to attend our next quarterly meeting. Note that, her name is Melike.\n",
            "AI:        Dear Melike, \n",
            "\n",
            "I am writing to request your attendance at our upcoming quarterly meeting. This important event will take place on October 15th, 2021, at 2pm. Your presence is essential to help us move forward with our goals and objectives. \n",
            "\n",
            "I look forward to seeing you there. \n",
            "\n",
            "Best regards, \n",
            "[Your Name]\n",
            "User \n",
            "Human: How I can travel from Rotterdam to New York? what are the possibilities?\n",
            "AI:        There are several options available for traveling from Rotterdam to New York, including flights, trains, and buses. Flights are offered by various airlines, including KLM Royal Dutch Airlines, Air France, and Delta. Train tickets can be purchased through the Netherlands Railways website. Buses can be booked through websites like FlixBus or Greyhound. It is recommended to book in advance to secure the best prices and availability.\n",
            "User \n",
            "Human: What are unique features of Dutch which other languages do not have them?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "       One unique feature of Dutch is the use of the word \"Yes\" to agree with a statement. For example, instead of saying \"Yes\", a Dutch person would say \"Ja\". Another feature is the use of bicycles as a primary mode of transportation in cities. In the Netherlands, cycling is seen as a healthy and sustainable way to get around. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What are unique features of Dutch languege?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "aPLYYmu1hVfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623ebe62-fea4-4ee9-aca6-2f639a6049ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What are those main factors which banks has to consider in bulding model taxonomy? write them in 10 bullet points.\n",
            "AI:      The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: How europian central bank supervises the banks in euro zone?\n",
            "AI:       The European Central Bank (ECB) supervises the banks in the Eurozone by setting minimum requirements for banks to meet in order to remain eligible for ECB funding. These requirements include having sufficient capital, maintaining adequate liquidity ratios, and complying with regulations such as anti-money laundering and counterfeiting laws. In addition, the ECB regularly checks the financial health of banks and may impose restrictions or penalties if necessary.\n",
            "User \n",
            "Human:\n",
            "Human: What are those 5 main factors which banks has to consider in bulding model taxonomy?\n",
            "AI:       The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: Write precise and consise email to my manage and ask her to attend our next quarterly meeting. Note that, her name is Melike.\n",
            "AI:        Dear Melike, \n",
            "\n",
            "I am writing to request your attendance at our upcoming quarterly meeting. This important event will take place on October 15th, 2021, at 2pm. Your presence is essential to help us move forward with our goals and objectives. \n",
            "\n",
            "I look forward to seeing you there. \n",
            "\n",
            "Best regards, \n",
            "[Your Name]\n",
            "User \n",
            "Human: How I can travel from Rotterdam to New York? what are the possibilities?\n",
            "AI:        There are several options available for traveling from Rotterdam to New York, including flights, trains, and buses. Flights are offered by various airlines, including KLM Royal Dutch Airlines, Air France, and Delta. Train tickets can be purchased through the Netherlands Railways website. Buses can be booked through websites like FlixBus or Greyhound. It is recommended to book in advance to secure the best prices and availability.\n",
            "User \n",
            "Human: What are unique features of Dutch which other languages do not have them?\n",
            "AI:        One unique feature of Dutch is the use of the word \"Yes\" to agree with a statement. For example, instead of saying \"Yes\", a Dutch person would say \"Ja\". Another feature is the use of bicycles as a primary mode of transportation in cities. In the Netherlands, cycling is seen as a healthy and sustainable way to get around. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human: What are unique features of Dutch languege?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "        Dutch has many unique features, such as using the word \"Yes\" to agree with a statement, and eating lunch later in the day. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What are the differencess of acustic violin and electric violin from playing perspective?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "G25c40VvhVh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa732af4-91fa-441e-e1c8-165d56c75e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How europian central bank supervises the banks in euro zone?\n",
            "AI:    The European Central Bank (ECB) supervises the banks in the Eurozone through various tools such as stress tests, regular inspections, and monitoring of banks’ balance sheets. The ECB also implements policies such as quantitative easing to stimulate economic growth and maintain price stability. In addition, the ECB has implemented new rules to increase transparency and accountability in the banking sector.\n",
            "User \n",
            "Human:\n",
            "Human: Write precise and consise email to my manage and ask her to attend our QBR meeting. Note that, her name is Melike.\n",
            "AI:      Dear Melike, \n",
            "\n",
            "I am writing to invite you to attend our upcoming Quality Assurance Review Meeting. This meeting will take place on [date] at [time]. I would be grateful if you could confirm your availability to join us. \n",
            "\n",
            "Thank you, \n",
            "[Name]\n",
            "User \n",
            "Human:\n",
            "Human: Summarize, The Basel Committee on Banking Supervision is responsible for developing and implementing regulations that ensure the stability and soundness of the global financial system. Its main responsibilities include setting standards for capital adequacy, liquidity requirements, and operational risk management. The committee also monitors and evaluates the implementation of these regulations by member countries to ensure compliance.\n",
            "AI:  \n",
            "The Basel Committee on Banking Supervision is an international organization that sets standards for the global financial system. Its main responsibilities include setting standards for capital adequacy, liquidity requirements, and operational risk management. The committee also monitors and evaluates the implementation of these regulations by member countries to ensure compliance.\n",
            "User \n",
            "Human: How I can travel from Rotterdam to New York? what are the possibilities?\n",
            "AI:  \n",
            "There are several ways to travel from Rotterdam to New York, including flights, trains, and buses. Flights are available from multiple airlines, with direct flights taking around 8 hours. Trains are also available, with options including high-speed rail services and local commuter trains. Finally, there are bus services available, with options including shuttle services and public transportation.\n",
            "User \n",
            "Human:\n",
            "Human: What are unique features if Dutch which no other kanguages do not have them?\n",
            "AI: \n",
            "The Netherlands is known for its tulips, windmills, and cheese. Dutch people are famous for their hospitality and love of cycling. Dutch culture is also unique in its approach to work and leisure, with many businesses closing early on Friday afternoons and weekends. Additionally, Dutch people are known for their love of technology, with the country being home to companies like Philips and ASML.\n",
            "User \n",
            "Human:\n",
            "Human: What are unique features if Dutch languege?\n",
            "AI:  \n",
            "Dutch is one of the few languages in Europe that still uses Latin characters, with some words and phrases still being used that are not commonly used in other languages. Dutch is also known for its use of humor and sarcasm, which can sometimes be difficult to understand for non-native speakers. Dutch people are also known for their love of coffee, with many cafes offering free refills and lattes.\n",
            "User \n",
            "Human: What are the differencess of acustic violin and electric violin from playing perspective?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " \n",
            "Acoustic violins require more physical effort to play due to the need to hold and manipulate the instrument. They also require more space and setup time. Electric violins, on the other hand, are easier to play due to the lack of physical effort required. They also require less setup time and space. However, they may not produce the same range of tones and dynamics as acoustic violins.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Does electric violin requires additional equipments to use? if so, what are them?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmgqOt3CTp5Z",
        "outputId": "5214ca0e-5745-4205-a585-5a1d6feb348d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How europian central bank supervises the banks in euro zone?\n",
            "AI:       The European Central Bank (ECB) supervises the banks in the Eurozone by setting minimum requirements for banks to meet in order to remain eligible for ECB funding. These requirements include having sufficient capital, maintaining adequate liquidity ratios, and complying with regulations such as anti-money laundering and counterfeiting laws. In addition, the ECB regularly checks the financial health of banks and may impose restrictions or penalties if necessary.\n",
            "User \n",
            "Human:\n",
            "Human: What are those 5 main factors which banks has to consider in bulding model taxonomy?\n",
            "AI:       The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: Write precise and consise email to my manage and ask her to attend our next quarterly meeting. Note that, her name is Melike.\n",
            "AI:        Dear Melike, \n",
            "\n",
            "I am writing to request your attendance at our upcoming quarterly meeting. This important event will take place on October 15th, 2021, at 2pm. Your presence is essential to help us move forward with our goals and objectives. \n",
            "\n",
            "I look forward to seeing you there. \n",
            "\n",
            "Best regards, \n",
            "[Your Name]\n",
            "User \n",
            "Human: How I can travel from Rotterdam to New York? what are the possibilities?\n",
            "AI:        There are several options available for traveling from Rotterdam to New York, including flights, trains, and buses. Flights are offered by various airlines, including KLM Royal Dutch Airlines, Air France, and Delta. Train tickets can be purchased through the Netherlands Railways website. Buses can be booked through websites like FlixBus or Greyhound. It is recommended to book in advance to secure the best prices and availability.\n",
            "User \n",
            "Human: What are unique features of Dutch which other languages do not have them?\n",
            "AI:        One unique feature of Dutch is the use of the word \"Yes\" to agree with a statement. For example, instead of saying \"Yes\", a Dutch person would say \"Ja\". Another feature is the use of bicycles as a primary mode of transportation in cities. In the Netherlands, cycling is seen as a healthy and sustainable way to get around. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human: What are unique features of Dutch languege?\n",
            "AI:         Dutch has many unique features, such as using the word \"Yes\" to agree with a statement, and eating lunch later in the day. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human:\n",
            "Human: Does electric violin requires additional equipments to use? if so, what are them?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "        Yes, an electric violin requires additional equipment to be used. Some of the common equipment needed include an amplifier, cables, and headphones. Depending on the type of instrument, additional accessories such as picks, stands, and cases may also be required.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Write one page summary about, geography of netherlands\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms6Im9nXUAUS",
        "outputId": "77fad78c-c018-4be9-8c80-bc1b7f5bdb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What are those 5 main factors which banks has to consider in bulding model taxonomy?\n",
            "AI:       The main factors that banks have to consider in building a model taxonomy include: \n",
            "- Identifying the purpose of the model\n",
            "- Determining the scope of the model\n",
            "- Defining the data elements and sources\n",
            "- Establishing the structure of the model\n",
            "- Developing the data validation process\n",
            "- Testing the model\n",
            "- Documenting the model\n",
            "- Implementing the model\n",
            "- Updating the model\n",
            "- Maintaining the model\n",
            "User \n",
            "Human:\n",
            "Human: Write precise and consise email to my manage and ask her to attend our next quarterly meeting. Note that, her name is Melike.\n",
            "AI:        Dear Melike, \n",
            "\n",
            "I am writing to request your attendance at our upcoming quarterly meeting. This important event will take place on October 15th, 2021, at 2pm. Your presence is essential to help us move forward with our goals and objectives. \n",
            "\n",
            "I look forward to seeing you there. \n",
            "\n",
            "Best regards, \n",
            "[Your Name]\n",
            "User \n",
            "Human: How I can travel from Rotterdam to New York? what are the possibilities?\n",
            "AI:        There are several options available for traveling from Rotterdam to New York, including flights, trains, and buses. Flights are offered by various airlines, including KLM Royal Dutch Airlines, Air France, and Delta. Train tickets can be purchased through the Netherlands Railways website. Buses can be booked through websites like FlixBus or Greyhound. It is recommended to book in advance to secure the best prices and availability.\n",
            "User \n",
            "Human: What are unique features of Dutch which other languages do not have them?\n",
            "AI:        One unique feature of Dutch is the use of the word \"Yes\" to agree with a statement. For example, instead of saying \"Yes\", a Dutch person would say \"Ja\". Another feature is the use of bicycles as a primary mode of transportation in cities. In the Netherlands, cycling is seen as a healthy and sustainable way to get around. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human: What are unique features of Dutch languege?\n",
            "AI:         Dutch has many unique features, such as using the word \"Yes\" to agree with a statement, and eating lunch later in the day. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human:\n",
            "Human: Does electric violin requires additional equipments to use? if so, what are them?\n",
            "AI:         Yes, an electric violin requires additional equipment to be used. Some of the common equipment needed include an amplifier, cables, and headphones. Depending on the type of instrument, additional accessories such as picks, stands, and cases may also be required.\n",
            "User \n",
            "Human: Write one page summary about, geography of netherlands\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "        The Netherlands is a country located in Western Europe, bordered by Belgium, Germany, and Luxembourg. The country is divided into twelve provinces, each of which is further divided into smaller municipalities. The population of the Netherlands is approximately 17.2 million people, making it one of the most densely populated countries in the world. The majority of the population lives in the southern part of the country, along the coast. The climate of the Netherlands varies depending on the region, ranging from mild summers in the south to cold winters in the north. The official language of the Netherlands is Dutch, although English is widely spoken.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Write one page summary of history of Netherlands.\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "9NtoubuahVlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c24f7e8-3a7b-4c68-c614-4bad1846ce36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Write precise and consise email to my manage and ask her to attend our next quarterly meeting. Note that, her name is Melike.\n",
            "AI:        Dear Melike, \n",
            "\n",
            "I am writing to request your attendance at our upcoming quarterly meeting. This important event will take place on October 15th, 2021, at 2pm. Your presence is essential to help us move forward with our goals and objectives. \n",
            "\n",
            "I look forward to seeing you there. \n",
            "\n",
            "Best regards, \n",
            "[Your Name]\n",
            "User \n",
            "Human: How I can travel from Rotterdam to New York? what are the possibilities?\n",
            "AI:        There are several options available for traveling from Rotterdam to New York, including flights, trains, and buses. Flights are offered by various airlines, including KLM Royal Dutch Airlines, Air France, and Delta. Train tickets can be purchased through the Netherlands Railways website. Buses can be booked through websites like FlixBus or Greyhound. It is recommended to book in advance to secure the best prices and availability.\n",
            "User \n",
            "Human: What are unique features of Dutch which other languages do not have them?\n",
            "AI:        One unique feature of Dutch is the use of the word \"Yes\" to agree with a statement. For example, instead of saying \"Yes\", a Dutch person would say \"Ja\". Another feature is the use of bicycles as a primary mode of transportation in cities. In the Netherlands, cycling is seen as a healthy and sustainable way to get around. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human: What are unique features of Dutch languege?\n",
            "AI:         Dutch has many unique features, such as using the word \"Yes\" to agree with a statement, and eating lunch later in the day. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human:\n",
            "Human: Does electric violin requires additional equipments to use? if so, what are them?\n",
            "AI:         Yes, an electric violin requires additional equipment to be used. Some of the common equipment needed include an amplifier, cables, and headphones. Depending on the type of instrument, additional accessories such as picks, stands, and cases may also be required.\n",
            "User \n",
            "Human: Write one page summary about, geography of netherlands\n",
            "AI:         The Netherlands is a country located in Western Europe, bordered by Belgium, Germany, and Luxembourg. The country is divided into twelve provinces, each of which is further divided into smaller municipalities. The population of the Netherlands is approximately 17.2 million people, making it one of the most densely populated countries in the world. The majority of the population lives in the southern part of the country, along the coast. The climate of the Netherlands varies depending on the region, ranging from mild summers in the south to cold winters in the north. The official language of the Netherlands is Dutch, although English is widely spoken.\n",
            "User \n",
            "Human: Write one page summary of history of Netherlands.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "         The Netherlands has a long history dating back to the Middle Ages. The country was first colonized by the Romans in AD 43, and then conquered by the Franks in AD 44. After the fall of the Roman Empire, the area was split into two parts, with the northern part becoming part of the Kingdom of Charlemagne. During the Renaissance, the Netherlands became a major center of art and culture, with famous painters such as Rembrandt van Rijn and Johannes Vermeer emerging from the country. During World War II, the Netherlands was occupied by Nazi Germany, leading to significant damage and loss of life. After the war, the country underwent a period of economic growth and cultural change. Today, the Netherlands is known for its vibrant arts scene, diverse cuisine, and tolerant society.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Why Utrecht is special for Dutch community?\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "4KII3fAnhVn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8f960a-1f47-430a-bcd9-a2f7bfcd8586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How I can travel from Rotterdam to New York? what are the possibilities?\n",
            "AI:        There are several options available for traveling from Rotterdam to New York, including flights, trains, and buses. Flights are offered by various airlines, including KLM Royal Dutch Airlines, Air France, and Delta. Train tickets can be purchased through the Netherlands Railways website. Buses can be booked through websites like FlixBus or Greyhound. It is recommended to book in advance to secure the best prices and availability.\n",
            "User \n",
            "Human: What are unique features of Dutch which other languages do not have them?\n",
            "AI:        One unique feature of Dutch is the use of the word \"Yes\" to agree with a statement. For example, instead of saying \"Yes\", a Dutch person would say \"Ja\". Another feature is the use of bicycles as a primary mode of transportation in cities. In the Netherlands, cycling is seen as a healthy and sustainable way to get around. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human: What are unique features of Dutch languege?\n",
            "AI:         Dutch has many unique features, such as using the word \"Yes\" to agree with a statement, and eating lunch later in the day. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human:\n",
            "Human: Does electric violin requires additional equipments to use? if so, what are them?\n",
            "AI:         Yes, an electric violin requires additional equipment to be used. Some of the common equipment needed include an amplifier, cables, and headphones. Depending on the type of instrument, additional accessories such as picks, stands, and cases may also be required.\n",
            "User \n",
            "Human: Write one page summary about, geography of netherlands\n",
            "AI:         The Netherlands is a country located in Western Europe, bordered by Belgium, Germany, and Luxembourg. The country is divided into twelve provinces, each of which is further divided into smaller municipalities. The population of the Netherlands is approximately 17.2 million people, making it one of the most densely populated countries in the world. The majority of the population lives in the southern part of the country, along the coast. The climate of the Netherlands varies depending on the region, ranging from mild summers in the south to cold winters in the north. The official language of the Netherlands is Dutch, although English is widely spoken.\n",
            "User \n",
            "Human: Write one page summary of history of Netherlands.\n",
            "AI:          The Netherlands has a long history dating back to the Middle Ages. The country was first colonized by the Romans in AD 43, and then conquered by the Franks in AD 44. After the fall of the Roman Empire, the area was split into two parts, with the northern part becoming part of the Kingdom of Charlemagne. During the Renaissance, the Netherlands became a major center of art and culture, with famous painters such as Rembrandt van Rijn and Johannes Vermeer emerging from the country. During World War II, the Netherlands was occupied by Nazi Germany, leading to significant damage and loss of life. After the war, the country underwent a period of economic growth and cultural change. Today, the Netherlands is known for its vibrant arts scene, diverse cuisine, and tolerant society.\n",
            "User \n",
            "Human: Why Utrecht is special for Dutch community?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "         Utrecht is the capital of the province of Utrecht in the central part of the Netherlands. It is home to over 700 years of history, and is known for its canals, parks, and medieval architecture. The city is home to many festivals and events throughout the year, including the annual Tulp Festival, celebrating tulips in spring. Utrecht is also home to many museums, including the National Museum of Antiquities, housing artifacts from ancient times. The city is also home to many universities, including the University of Utrecht, one of the oldest universities in the world. Utrecht is also home to many green spaces, parks, and bike paths, making it a popular destination for those looking to relax and enjoy nature.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"My friend's name is Magda, write a poem for her birthday.\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "lbzlghfKhVrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce6aea5-6174-4189-bfa0-70b0fa962471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI.\n",
            "The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What are unique features of Dutch which other languages do not have them?\n",
            "AI:        One unique feature of Dutch is the use of the word \"Yes\" to agree with a statement. For example, instead of saying \"Yes\", a Dutch person would say \"Ja\". Another feature is the use of bicycles as a primary mode of transportation in cities. In the Netherlands, cycling is seen as a healthy and sustainable way to get around. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human: What are unique features of Dutch languege?\n",
            "AI:         Dutch has many unique features, such as using the word \"Yes\" to agree with a statement, and eating lunch later in the day. Additionally, Dutch people often eat their meals later in the day, typically between 12pm and 2pm. This is due to the fact that lunch is considered the biggest meal of the day in the Netherlands.\n",
            "User \n",
            "Human:\n",
            "Human: Does electric violin requires additional equipments to use? if so, what are them?\n",
            "AI:         Yes, an electric violin requires additional equipment to be used. Some of the common equipment needed include an amplifier, cables, and headphones. Depending on the type of instrument, additional accessories such as picks, stands, and cases may also be required.\n",
            "User \n",
            "Human: Write one page summary about, geography of netherlands\n",
            "AI:         The Netherlands is a country located in Western Europe, bordered by Belgium, Germany, and Luxembourg. The country is divided into twelve provinces, each of which is further divided into smaller municipalities. The population of the Netherlands is approximately 17.2 million people, making it one of the most densely populated countries in the world. The majority of the population lives in the southern part of the country, along the coast. The climate of the Netherlands varies depending on the region, ranging from mild summers in the south to cold winters in the north. The official language of the Netherlands is Dutch, although English is widely spoken.\n",
            "User \n",
            "Human: Write one page summary of history of Netherlands.\n",
            "AI:          The Netherlands has a long history dating back to the Middle Ages. The country was first colonized by the Romans in AD 43, and then conquered by the Franks in AD 44. After the fall of the Roman Empire, the area was split into two parts, with the northern part becoming part of the Kingdom of Charlemagne. During the Renaissance, the Netherlands became a major center of art and culture, with famous painters such as Rembrandt van Rijn and Johannes Vermeer emerging from the country. During World War II, the Netherlands was occupied by Nazi Germany, leading to significant damage and loss of life. After the war, the country underwent a period of economic growth and cultural change. Today, the Netherlands is known for its vibrant arts scene, diverse cuisine, and tolerant society.\n",
            "User \n",
            "Human: Why Utrecht is special for Dutch community?\n",
            "AI:          Utrecht is the capital of the province of Utrecht in the central part of the Netherlands. It is home to over 700 years of history, and is known for its canals, parks, and medieval architecture. The city is home to many festivals and events throughout the year, including the annual Tulp Festival, celebrating tulips in spring. Utrecht is also home to many museums, including the National Museum of Antiquities, housing artifacts from ancient times. The city is also home to many universities, including the University of Utrecht, one of the oldest universities in the world. Utrecht is also home to many green spaces, parks, and bike paths, making it a popular destination for those looking to relax and enjoy nature.\n",
            "User \n",
            "Human: My friend's name is Magda, write a poem for her birthday.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "          Magda, you are so wonderful,\n",
            "Your spirit is like a rainbow.\n",
            "You bring joy wherever you go,\n",
            "And make everyone feel happy.\n",
            "\n",
            "Happy Birthday to you!\n",
            "May all your dreams come true.\n",
            "I hope this special day brings you joy,\n",
            "And makes you smile from ear to ear.\n",
            "User \n",
            "Human:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "euoWfk76hVwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cmQHJuefhVz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LkGp4rdqhV3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lxgV2AwUhV55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !streamlit run chatbot_app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "4-Bs38vD_gLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJigMkPHgXUf",
        "outputId": "10d53ad3-68fa-4e82-ccc6-c74e5abd4d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul 15 13:09:43 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    27W /  70W |   8351MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = model.generation_config\n",
        "generation_config.temperature = 0\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.max_new_tokens = 256\n",
        "generation_config.use_cache = False\n",
        "generation_config.repetition_penalty = 1.7\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id\n",
        "generation_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HSP4uschELo",
        "outputId": "db6eecd3-91cc-4a6d-9f9a-77781a5a2837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerationConfig {\n",
              "  \"_from_model_config\": true,\n",
              "  \"bos_token_id\": 1,\n",
              "  \"eos_token_id\": 11,\n",
              "  \"max_new_tokens\": 256,\n",
              "  \"pad_token_id\": 11,\n",
              "  \"repetition_penalty\": 1.7,\n",
              "  \"temperature\": 0,\n",
              "  \"transformers_version\": \"4.30.0\",\n",
              "  \"use_cache\": false\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u5d_toJiem-",
        "outputId": "29f42490-08b1-4322-d108-9cc207aa5a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RWConfig {\n",
              "  \"_name_or_path\": \"tiiuae/falcon-7b-instruct\",\n",
              "  \"alibi\": false,\n",
              "  \"apply_residual_connection_post_layernorm\": false,\n",
              "  \"architectures\": [\n",
              "    \"RWForCausalLM\"\n",
              "  ],\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"auto_map\": {\n",
              "    \"AutoConfig\": \"tiiuae/falcon-7b-instruct--configuration_RW.RWConfig\",\n",
              "    \"AutoModelForCausalLM\": \"tiiuae/falcon-7b-instruct--modelling_RW.RWForCausalLM\"\n",
              "  },\n",
              "  \"bias\": false,\n",
              "  \"bos_token_id\": 11,\n",
              "  \"eos_token_id\": 11,\n",
              "  \"hidden_dropout\": 0.0,\n",
              "  \"hidden_size\": 4544,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"model_type\": \"RefinedWebModel\",\n",
              "  \"multi_query\": true,\n",
              "  \"n_head\": 71,\n",
              "  \"n_layer\": 32,\n",
              "  \"parallel_attn\": true,\n",
              "  \"quantization_config\": {\n",
              "    \"bnb_4bit_compute_dtype\": \"float32\",\n",
              "    \"bnb_4bit_quant_type\": \"fp4\",\n",
              "    \"bnb_4bit_use_double_quant\": false,\n",
              "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
              "    \"llm_int8_has_fp16_weight\": false,\n",
              "    \"llm_int8_skip_modules\": null,\n",
              "    \"llm_int8_threshold\": 6.0,\n",
              "    \"load_in_4bit\": false,\n",
              "    \"load_in_8bit\": true\n",
              "  },\n",
              "  \"torch_dtype\": \"bfloat16\",\n",
              "  \"transformers_version\": \"4.30.0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 65024\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
        "\n",
        "Current conversation:\n",
        "\n",
        "Human: Who is Dwight K Schrute?\n",
        "AI:\n",
        "\"\"\".strip()\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "input_ids = input_ids.to(model.device)"
      ],
      "metadata": {
        "id": "7FHbekhIhMiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        generation_config=generation_config,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifAkcBP_hR0V",
        "outputId": "aaa10f85-e483-439c-8fc1-f29b5aecf60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.56 s, sys: 0 ns, total: 7.56 s\n",
            "Wall time: 7.55 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Mi5rPFhVk4",
        "outputId": "b88196e0-42ea-4293-a49c-a324e2011a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Who is Dwight K Schrute?\n",
            "AI: Dwight K Schrute is a fictional character in the American television series \"The Office\". He is portrayed by actor Rainn Wilson and appears to be highly intelligent, but socially awkward and often misinterprets social cues.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop LLM From Rambling"
      ],
      "metadata": {
        "id": "jUjR8xlZS_07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StopGenerationCriteria(StoppingCriteria):\n",
        "    def __init__(\n",
        "        self, tokens: List[List[str]], tokenizer: AutoTokenizer, device: torch.device\n",
        "    ):\n",
        "        stop_token_ids = [tokenizer.convert_tokens_to_ids(t) for t in tokens]\n",
        "        self.stop_token_ids = [\n",
        "            torch.tensor(x, dtype=torch.long, device=device) for x in stop_token_ids\n",
        "        ]\n",
        "\n",
        "    def __call__(\n",
        "        self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs\n",
        "    ) -> bool:\n",
        "        for stop_ids in self.stop_token_ids:\n",
        "            if torch.eq(input_ids[0][-len(stop_ids) :], stop_ids).all():\n",
        "                return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "AZty_vG7VEv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_tokens = [[\"Human\", \":\"], [\"AI\", \":\"]]\n",
        "stopping_criteria = StoppingCriteriaList(\n",
        "    [StopGenerationCriteria(stop_tokens, tokenizer, model.device)]\n",
        ")"
      ],
      "metadata": {
        "id": "sRRAYC5BQzRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_pipeline = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    task=\"text-generation\",\n",
        "    stopping_criteria=stopping_criteria,\n",
        "    generation_config=generation_config,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generation_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSKfZDo_qPPa",
        "outputId": "e495b953-2934-48bd-de98-efe3e7f2bb28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'RWForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = llm(prompt)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPuBvTNwMJbt",
        "outputId": "a1e31fbd-abed-40df-d9ab-65e056cda42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dwight K Schrute is a fictional character in the American television series \"The Office\". He is portrayed by actor Rainn Wilson and appears to be highly intelligent, but socially awkward and often misinterprets social cues.\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversation Chain"
      ],
      "metadata": {
        "id": "0kdpOzTiMP_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = ConversationChain(llm=llm)\n",
        "print(chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ELYTpMjf94b",
        "outputId": "c5eedfc2-28a2-4805-b5f7-e249e32fdfc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Prompt"
      ],
      "metadata": {
        "id": "oa1KjV_0MTZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "The following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office.\n",
        "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical.\n",
        "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Human: {input}\n",
        "AI:\"\"\".strip()\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
        "\n",
        "print(template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t35AL-kodESQ",
        "outputId": "3c8afe14-4267-4329-f61e-c2c5b35c6fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office. \n",
            "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical. \n",
            "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"history\", k=6, return_only_outputs=True\n",
        ")\n",
        "\n",
        "chain = ConversationChain(llm=llm, memory=memory, prompt=prompt, verbose=True)"
      ],
      "metadata": {
        "id": "f52SL8WUdEj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\"\n",
        "res = chain.predict(input=text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlD1uZ7ozfU8",
        "outputId": "1093553e-2c58-409d-9f28-f99854d6fd63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office. \n",
            "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical. \n",
            "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " SchruteAuto\n",
            "User \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning Output"
      ],
      "metadata": {
        "id": "bocD-qf9MnCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CleanupOutputParser(BaseOutputParser):\n",
        "    def parse(self, text: str) -> str:\n",
        "        user_pattern = r\"\\nUser\"\n",
        "        text = re.sub(user_pattern, \"\", text)\n",
        "        human_pattern = r\"\\nHuman:\"\n",
        "        text = re.sub(human_pattern, \"\", text)\n",
        "        ai_pattern = r\"\\nAI:\"\n",
        "        return re.sub(ai_pattern, \"\", text).strip()\n",
        "\n",
        "    @property\n",
        "    def _type(self) -> str:\n",
        "        return \"output_parser\""
      ],
      "metadata": {
        "id": "-NcWkQzf_XGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"history\", k=6, return_only_outputs=True\n",
        ")\n",
        "\n",
        "chain = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    prompt=prompt,\n",
        "    output_parser=CleanupOutputParser(),\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "QueTe0d2APBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try It Out"
      ],
      "metadata": {
        "id": "y061aQtkNJ4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\"\n",
        "res = chain(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSr8R96qAdIm",
        "outputId": "dbbd7068-da17-415d-b7fd-db50d6a98c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office. \n",
            "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical. \n",
            "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yclkn33Evcz",
        "outputId": "fa60d291-4b86-4d19-bdd2-ecb30c7ccfe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input', 'history', 'response'])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMAWA60zE0Il",
        "outputId": "31d514aa-d228-46e4-e98f-342ea61c4798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SchruteAuto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Think of a slogan for the company\"\n",
        "res = chain(text)\n",
        "print(res[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix079vCBgER1",
        "outputId": "34db13ee-2033-4f61-9242-22be942d8e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office. \n",
            "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical. \n",
            "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\n",
            "AI: SchruteAuto\n",
            "Human: Think of a slogan for the company\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Drive Big With SchruteAuto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Choose a domain name for the company\"\n",
        "res = chain(text)\n",
        "print(res[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl3r71V7GCda",
        "outputId": "a9bc7a04-4aa0-4447-b533-7f6efebfc8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office. \n",
            "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical. \n",
            "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\n",
            "AI: SchruteAuto\n",
            "Human: Think of a slogan for the company\n",
            "AI: Drive Big With SchruteAuto\n",
            "Human: Choose a domain name for the company\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "schruteauto.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Write a tweet that introduces the company and introduces the first car built by the company\"\n",
        "res = chain(text)\n",
        "print(res[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5XDNvPPtf3P",
        "outputId": "1d57eae3-1af8-4766-c9f3-b5e2119eada2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office. \n",
            "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical. \n",
            "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\n",
            "AI: SchruteAuto\n",
            "Human: Think of a slogan for the company\n",
            "AI: Drive Big With SchruteAuto\n",
            "Human: Choose a domain name for the company\n",
            "AI: schruteauto.com\n",
            "Human: Write a tweet that introduces the company and introduces the first car built by the company\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Introducing SchruteAuto! We build powerful family cars with big V8 engines. Check out our website for more information: schruteauto.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Write a short marketing email to sell the first car from the company - 700HP family sedan from a supercharged V8 with manual gearbox.\"\n",
        "res = chain(text)\n",
        "print(res[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41LDn-8KyKCV",
        "outputId": "e752e624-2e17-4309-8018-de0e0fc14131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office. \n",
            "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical. \n",
            "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\n",
            "AI: SchruteAuto\n",
            "Human: Think of a slogan for the company\n",
            "AI: Drive Big With SchruteAuto\n",
            "Human: Choose a domain name for the company\n",
            "AI: schruteauto.com\n",
            "Human: Write a tweet that introduces the company and introduces the first car built by the company\n",
            "AI: Introducing SchruteAuto! We build powerful family cars with big V8 engines. Check out our website for more information: schruteauto.com\n",
            "Human: Write a short marketing email to sell the first car from the company - 700HP family sedan from a supercharged V8 with manual gearbox.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Subject: Experience Power And Performance In Your Family Car\n",
            "Body:\n",
            "Are you looking for a powerful family car that can handle any road? Look no further than SchruteAuto! Our 700HP family sedan comes equipped with a supercharged V8 engine and a manual gearbox, so you can experience power and performance in your own driveway. Visit schruteauto.com today to find out more!\n"
          ]
        }
      ]
    }
  ]
}